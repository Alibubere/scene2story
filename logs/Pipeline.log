2025-12-07 21:00:43,387 - INFO - Logging initialize successfully
2025-12-07 21:00:43,522 - INFO - Loaded 29000 rows for split='train'.
2025-12-07 21:00:44,864 - INFO - Built 29000 samples from annotaions
2025-12-07 21:00:44,865 - INFO - Total samples: 29000
2025-12-07 21:03:51,037 - INFO - Logging initialize successfully
2025-12-07 21:03:51,172 - INFO - Loaded 29000 rows for split='train'.
2025-12-07 21:03:52,497 - INFO - Built 29000 samples from annotaions
2025-12-07 21:03:52,498 - INFO - Total samples: 29000
2025-12-07 21:04:50,218 - INFO - Logging initialize successfully
2025-12-07 21:04:50,338 - INFO - Loaded 29000 rows for split='train'.
2025-12-07 21:04:51,637 - INFO - Built 29000 samples from annotaions
2025-12-07 21:04:51,639 - INFO - Total samples: 29000
2025-12-08 12:40:20,696 - INFO - Logging initialize successfully
2025-12-08 12:40:20,928 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 12:40:23,343 - INFO - Built 29000 samples from annotaions
2025-12-08 12:40:23,349 - INFO - Total samples: 29000
2025-12-08 12:40:43,724 - INFO - Logging initialize successfully
2025-12-08 12:40:43,924 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 12:40:45,952 - INFO - Built 29000 samples from annotaions
2025-12-08 12:40:45,952 - INFO - Total samples: 29000
2025-12-08 12:57:57,493 - INFO - Logging initialize successfully
2025-12-08 12:57:57,722 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 12:57:59,880 - INFO - Built 29000 samples from annotaions
2025-12-08 12:57:59,880 - INFO - Total samples: 29000
2025-12-08 12:58:31,813 - INFO - Logging initialize successfully
2025-12-08 12:58:32,009 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 12:58:33,580 - INFO - Built 29000 samples from annotaions
2025-12-08 12:58:33,580 - INFO - Total samples: 29000
2025-12-08 12:59:02,916 - INFO - Logging initialize successfully
2025-12-08 12:59:03,118 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 12:59:04,940 - INFO - Built 29000 samples from annotaions
2025-12-08 12:59:04,940 - INFO - Total samples: 29000
2025-12-08 13:00:27,376 - INFO - Logging initialize successfully
2025-12-08 13:00:27,582 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 13:00:29,266 - INFO - Built 29000 samples from annotaions
2025-12-08 13:00:29,266 - INFO - Total samples: 29000
2025-12-08 13:00:45,144 - INFO - Logging initialize successfully
2025-12-08 13:00:45,366 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 13:00:47,346 - INFO - Built 29000 samples from annotaions
2025-12-08 13:00:47,346 - INFO - Total samples: 29000
2025-12-08 13:03:33,287 - INFO - Logging initialize successfully
2025-12-08 13:03:33,505 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 13:03:35,705 - INFO - Built 29000 samples from annotaions
2025-12-08 13:03:35,712 - INFO - Total samples: 29000
2025-12-08 14:03:23,882 - INFO - Logging initialize successfully
2025-12-08 14:03:24,024 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:03:25,572 - INFO - Built 29000 samples from annotaions
2025-12-08 14:03:25,572 - INFO - Total samples: 29000
2025-12-08 14:04:24,621 - INFO - Logging initialize successfully
2025-12-08 14:04:24,813 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:04:26,879 - INFO - Built 29000 samples from annotaions
2025-12-08 14:04:26,879 - INFO - Total samples: 29000
2025-12-08 14:06:13,308 - INFO - Logging initialize successfully
2025-12-08 14:06:13,444 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:06:15,034 - INFO - Built 29000 samples from annotaions
2025-12-08 14:06:15,034 - INFO - Total samples: 29000
2025-12-08 14:08:06,507 - INFO - Logging initialize successfully
2025-12-08 14:08:06,721 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:08:08,769 - INFO - Built 29000 samples from annotaions
2025-12-08 14:08:08,769 - INFO - Total samples: 29000
2025-12-08 14:08:46,488 - INFO - Logging initialize successfully
2025-12-08 14:08:46,687 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:08:49,019 - INFO - Built 29000 samples from annotaions
2025-12-08 14:08:49,025 - INFO - Total samples: 29000
2025-12-08 14:10:03,485 - INFO - Logging initialize successfully
2025-12-08 14:10:03,695 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:10:05,465 - INFO - Built 29000 samples from annotaions
2025-12-08 14:10:05,465 - INFO - Total samples: 29000
2025-12-08 14:10:53,535 - INFO - Logging initialize successfully
2025-12-08 14:10:53,744 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:10:55,346 - INFO - Built 29000 samples from annotaions
2025-12-08 14:10:55,346 - INFO - Total samples: 29000
2025-12-08 14:12:18,991 - INFO - Logging initialize successfully
2025-12-08 14:12:19,223 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:12:21,683 - INFO - Built 29000 samples from annotaions
2025-12-08 14:12:21,683 - INFO - Total samples: 29000
2025-12-08 14:20:35,771 - INFO - Logging initialize successfully
2025-12-08 14:20:36,004 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:20:38,388 - INFO - Built 29000 samples from annotaions
2025-12-08 14:20:38,388 - INFO - Total samples: 29000
2025-12-08 14:22:10,097 - INFO - Logging initialize successfully
2025-12-08 14:22:10,317 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:22:12,671 - INFO - Built 29000 samples from annotaions
2025-12-08 14:22:12,671 - INFO - Total samples: 29000
2025-12-08 14:25:48,144 - INFO - Logging initialize successfully
2025-12-08 14:25:48,360 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:25:50,967 - INFO - Built 29000 samples from annotaions
2025-12-08 14:25:50,967 - INFO - Total samples: 29000
2025-12-08 14:34:33,027 - INFO - Logging initialize successfully
2025-12-08 14:34:33,251 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:34:35,757 - INFO - Built 29000 samples from annotaions
2025-12-08 14:34:35,761 - INFO - Total samples: 29000
2025-12-08 14:35:07,901 - INFO - Logging initialize successfully
2025-12-08 14:35:08,121 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:35:10,496 - INFO - Built 29000 samples from annotaions
2025-12-08 14:35:10,496 - INFO - Total samples: 29000
2025-12-08 14:36:31,954 - INFO - Logging initialize successfully
2025-12-08 14:36:32,178 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:36:34,612 - INFO - Built 29000 samples from annotaions
2025-12-08 14:36:34,613 - INFO - Total samples: 29000
2025-12-08 14:38:25,806 - INFO - Logging initialize successfully
2025-12-08 14:38:26,021 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:38:28,446 - INFO - Built 29000 samples from annotaions
2025-12-08 14:38:28,448 - INFO - Total samples: 29000
2025-12-08 14:40:02,087 - INFO - Logging initialize successfully
2025-12-08 14:40:02,303 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:40:04,784 - INFO - Built 29000 samples from annotaions
2025-12-08 14:40:04,784 - INFO - Total samples: 29000
2025-12-08 14:47:33,387 - INFO - Logging initialize successfully
2025-12-08 14:47:33,625 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:47:36,124 - INFO - Built 29000 samples from annotaions
2025-12-08 14:47:36,124 - INFO - Total samples: 29000
2025-12-08 14:48:55,038 - INFO - Logging initialize successfully
2025-12-08 14:48:55,276 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:48:57,718 - INFO - Built 29000 samples from annotaions
2025-12-08 14:48:57,718 - INFO - Total samples: 29000
2025-12-08 14:48:57,881 - INFO - Built 29000 samples for story 
2025-12-08 14:49:06,881 - INFO - Logging initialize successfully
2025-12-08 14:49:07,091 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:49:09,475 - INFO - Built 29000 samples from annotaions
2025-12-08 14:49:09,475 - INFO - Total samples: 29000
2025-12-08 14:49:09,634 - INFO - Built 29000 samples for story 
2025-12-08 14:49:17,233 - INFO - Logging initialize successfully
2025-12-08 14:49:17,518 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:49:19,907 - INFO - Built 29000 samples from annotaions
2025-12-08 14:49:19,907 - INFO - Total samples: 29000
2025-12-08 14:49:20,062 - INFO - Built 29000 samples for story 
2025-12-08 14:50:28,757 - INFO - Logging initialize successfully
2025-12-08 14:50:28,986 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:50:31,428 - INFO - Built 29000 samples from annotaions
2025-12-08 14:50:31,430 - INFO - Total samples: 29000
2025-12-08 14:50:31,623 - INFO - Built 29000 samples for story 
2025-12-08 14:51:27,027 - INFO - Logging initialize successfully
2025-12-08 14:51:27,249 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 14:51:29,605 - INFO - Built 29000 samples from annotaions
2025-12-08 14:51:29,606 - INFO - Total samples: 29000
2025-12-08 14:51:29,749 - INFO - Built 29000 samples for story 
2025-12-08 15:04:51,266 - INFO - Logging initialize successfully
2025-12-08 15:04:51,396 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:04:52,678 - INFO - Built 29000 samples from annotaions
2025-12-08 15:04:52,688 - INFO - Total samples: 29000
2025-12-08 15:04:52,765 - INFO - Built 29000 samples for story 
2025-12-08 15:05:02,790 - INFO - Logging initialize successfully
2025-12-08 15:05:02,920 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:05:04,187 - INFO - Built 29000 samples from annotaions
2025-12-08 15:05:04,187 - INFO - Total samples: 29000
2025-12-08 15:05:04,260 - INFO - Built 29000 samples for story 
2025-12-08 15:06:15,073 - INFO - Logging initialize successfully
2025-12-08 15:06:15,207 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:06:16,467 - INFO - Built 29000 samples from annotaions
2025-12-08 15:06:16,467 - INFO - Total samples: 29000
2025-12-08 15:06:16,562 - INFO - Built 29000 samples for story 
2025-12-08 15:16:40,263 - INFO - Logging initialize successfully
2025-12-08 15:16:40,384 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:16:41,701 - INFO - Built 29000 samples from annotaions
2025-12-08 15:16:41,701 - INFO - Total samples: 29000
2025-12-08 15:16:41,784 - INFO - Built 29000 samples for story 
2025-12-08 15:16:59,301 - INFO - Logging initialize successfully
2025-12-08 15:16:59,425 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:17:00,725 - INFO - Built 29000 samples from annotaions
2025-12-08 15:17:00,725 - INFO - Total samples: 29000
2025-12-08 15:17:00,814 - INFO - Built 29000 samples for story 
2025-12-08 15:18:10,755 - INFO - Logging initialize successfully
2025-12-08 15:18:10,892 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:18:12,172 - INFO - Built 29000 samples from annotaions
2025-12-08 15:18:12,172 - INFO - Total samples: 29000
2025-12-08 15:18:12,260 - INFO - Built 29000 samples for story 
2025-12-08 15:27:27,312 - INFO - Logging initialize successfully
2025-12-08 15:28:26,896 - INFO - Logging initialize successfully
2025-12-08 15:28:27,018 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:28:28,307 - INFO - Built 29000 samples from annotaions
2025-12-08 15:28:28,307 - INFO - Total samples: 29000
2025-12-08 15:28:28,400 - INFO - Built 29000 samples for story 
2025-12-08 15:32:14,314 - INFO - Logging initialize successfully
2025-12-08 15:32:14,435 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:32:15,751 - INFO - Built 29000 samples from annotaions
2025-12-08 15:32:15,751 - INFO - Total samples: 29000
2025-12-08 15:32:15,826 - INFO - Built 29000 samples for story 
2025-12-08 15:37:15,215 - INFO - Logging initialize successfully
2025-12-08 15:37:15,356 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:37:16,640 - INFO - Built 29000 samples from annotaions
2025-12-08 15:37:16,656 - INFO - Total samples: 29000
2025-12-08 15:37:16,738 - INFO - Built 29000 samples for story 
2025-12-08 15:37:17,187 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-08 15:38:45,152 - INFO - Logging initialize successfully
2025-12-08 15:38:45,272 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:38:46,595 - INFO - Built 29000 samples from annotaions
2025-12-08 15:38:46,596 - INFO - Total samples: 29000
2025-12-08 15:38:46,676 - INFO - Built 29000 samples for story 
2025-12-08 15:38:47,059 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-08 15:39:58,266 - INFO - Logging initialize successfully
2025-12-08 15:39:58,404 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:39:59,732 - INFO - Built 29000 samples from annotaions
2025-12-08 15:39:59,734 - INFO - Total samples: 29000
2025-12-08 15:39:59,820 - INFO - Built 29000 samples for story 
2025-12-08 15:40:14,267 - INFO - Logging initialize successfully
2025-12-08 15:40:14,402 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 15:40:15,727 - INFO - Built 29000 samples from annotaions
2025-12-08 15:40:15,727 - INFO - Total samples: 29000
2025-12-08 15:40:15,819 - INFO - Built 29000 samples for story 
2025-12-08 15:40:15,966 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-08 17:18:21,274 - INFO - Logging initialize successfully
2025-12-08 17:18:21,417 - INFO - Loaded 1000 rows for split='test'.
2025-12-08 17:18:21,475 - INFO - Built 1000 samples from annotaions
2025-12-08 17:18:21,475 - INFO - Total samples: 1000
2025-12-08 17:18:21,478 - INFO - Built 1000 samples for story 
2025-12-08 17:18:21,478 - INFO - Cleaned data saved to data/processed\stories_test.jsonl
2025-12-08 19:50:18,596 - INFO - Logging initialize successfully
2025-12-08 19:50:18,740 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 19:50:20,117 - INFO - Built 29000 samples from annotaions
2025-12-08 19:50:20,117 - INFO - Total samples: 29000
2025-12-08 19:50:20,186 - INFO - Built 29000 samples for story 
2025-12-08 19:50:20,327 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-08 19:51:36,810 - INFO - Logging initialize successfully
2025-12-08 19:51:36,948 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 19:51:38,317 - INFO - Built 29000 samples from annotaions
2025-12-08 19:51:38,317 - INFO - Total samples: 29000
2025-12-08 19:51:38,379 - INFO - Built 29000 samples for story 
2025-12-08 19:51:38,524 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-08 19:56:15,571 - INFO - Logging initialize successfully
2025-12-08 19:56:15,710 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 19:56:17,073 - INFO - Built 29000 samples from annotaions
2025-12-08 19:56:17,073 - INFO - Total samples: 29000
2025-12-08 19:56:17,140 - INFO - Built 29000 samples for story 
2025-12-08 19:56:17,279 - INFO - Cleaned data saved to C:\Users\MUIN\Desktop\Ali\scene2story\data\processed\stories_train.jsonl
2025-12-08 19:57:17,218 - INFO - Logging initialize successfully
2025-12-08 19:59:10,212 - INFO - Logging initialize successfully
2025-12-08 19:59:10,345 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 19:59:11,724 - INFO - Built 29000 samples from annotaions
2025-12-08 19:59:11,725 - INFO - Total samples: 29000
2025-12-08 19:59:11,791 - INFO - Built 29000 samples for story 
2025-12-08 19:59:11,933 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-08 19:59:11,933 - ERROR - Data path must ends with .jsonl but got data/processed/stories_train_jsonl
2025-12-08 19:59:29,299 - INFO - Logging initialize successfully
2025-12-08 19:59:29,437 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 19:59:30,810 - INFO - Built 29000 samples from annotaions
2025-12-08 19:59:30,810 - INFO - Total samples: 29000
2025-12-08 19:59:30,879 - INFO - Built 29000 samples for story 
2025-12-08 19:59:31,027 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-08 20:01:17,963 - INFO - Logging initialize successfully
2025-12-08 20:01:18,095 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:01:19,485 - INFO - Built 29000 samples from annotaions
2025-12-08 20:01:19,485 - INFO - Total samples: 29000
2025-12-08 20:01:19,553 - INFO - Built 29000 samples for story 
2025-12-08 20:04:14,575 - INFO - Logging initialize successfully
2025-12-08 20:04:14,714 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:04:16,089 - INFO - Built 29000 samples from annotaions
2025-12-08 20:04:16,091 - INFO - Total samples: 29000
2025-12-08 20:04:16,157 - INFO - Built 29000 samples for story 
2025-12-08 20:04:28,896 - INFO - Logging initialize successfully
2025-12-08 20:04:29,018 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:04:30,332 - INFO - Built 29000 samples from annotaions
2025-12-08 20:04:30,332 - INFO - Total samples: 29000
2025-12-08 20:04:30,404 - INFO - Built 29000 samples for story 
2025-12-08 20:04:30,550 - INFO - Cleaned data saved to data/processed/stories_train.jsonl
2025-12-08 20:04:50,324 - INFO - Logging initialize successfully
2025-12-08 20:04:50,439 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:04:51,809 - INFO - Built 29000 samples from annotaions
2025-12-08 20:04:51,824 - INFO - Total samples: 29000
2025-12-08 20:04:51,889 - INFO - Built 29000 samples for story 
2025-12-08 20:04:52,032 - INFO - Cleaned data saved to data/processed/stories_train.jsonl
2025-12-08 20:06:12,870 - INFO - Logging initialize successfully
2025-12-08 20:06:12,985 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:06:14,336 - INFO - Built 29000 samples from annotaions
2025-12-08 20:06:14,336 - INFO - Total samples: 29000
2025-12-08 20:06:14,391 - INFO - Built 29000 samples for story 
2025-12-08 20:06:32,820 - INFO - Logging initialize successfully
2025-12-08 20:06:32,955 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:06:34,282 - INFO - Built 29000 samples from annotaions
2025-12-08 20:06:34,289 - INFO - Total samples: 29000
2025-12-08 20:06:34,351 - INFO - Built 29000 samples for story 
2025-12-08 20:06:34,504 - INFO - Cleaned data saved to data/processed/stories_train.jsonl
2025-12-08 20:07:00,459 - INFO - Logging initialize successfully
2025-12-08 20:07:00,567 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:07:01,917 - INFO - Built 29000 samples from annotaions
2025-12-08 20:07:01,933 - INFO - Total samples: 29000
2025-12-08 20:07:01,989 - INFO - Built 29000 samples for story 
2025-12-08 20:07:02,142 - INFO - Cleaned data saved to data/processed/stories_train.jsonl
2025-12-08 20:11:44,809 - INFO - Logging initialize successfully
2025-12-08 20:11:44,926 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:11:46,287 - INFO - Built 29000 samples from annotaions
2025-12-08 20:11:46,290 - INFO - Total samples: 29000
2025-12-08 20:11:46,354 - INFO - Built 29000 samples for story 
2025-12-08 20:11:46,509 - INFO - Cleaned data saved to data/processed/stories_train.jsonl
2025-12-08 20:12:54,762 - INFO - Logging initialize successfully
2025-12-08 20:12:54,898 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:12:56,258 - INFO - Built 29000 samples from annotaions
2025-12-08 20:12:56,258 - INFO - Total samples: 29000
2025-12-08 20:12:56,336 - INFO - Built 29000 samples for story 
2025-12-08 20:12:56,481 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-08 20:14:24,188 - INFO - Logging initialize successfully
2025-12-08 20:14:24,325 - INFO - Loaded 29000 rows for split='train'.
2025-12-08 20:14:25,720 - INFO - Built 29000 samples from annotaions
2025-12-08 20:14:25,725 - INFO - Total samples: 29000
2025-12-08 20:14:25,782 - INFO - Built 29000 samples for story 
2025-12-08 20:14:25,935 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 13:52:02,717 - INFO - Logging initialize successfully
2025-12-09 13:52:02,878 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 13:52:04,205 - INFO - Built 29000 samples from annotaions
2025-12-09 13:52:04,205 - INFO - Total samples: 29000
2025-12-09 13:52:04,274 - INFO - Built 29000 samples for story 
2025-12-09 13:52:04,413 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 13:53:13,130 - INFO - Logging initialize successfully
2025-12-09 13:53:13,251 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 13:53:14,546 - INFO - Built 29000 samples from annotaions
2025-12-09 13:53:14,546 - INFO - Total samples: 29000
2025-12-09 13:53:14,619 - INFO - Built 29000 samples for story 
2025-12-09 13:53:14,768 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 13:54:40,409 - INFO - Logging initialize successfully
2025-12-09 13:54:40,542 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 13:54:41,837 - INFO - Built 29000 samples from annotaions
2025-12-09 13:54:41,837 - INFO - Total samples: 29000
2025-12-09 13:54:41,910 - INFO - Built 29000 samples for story 
2025-12-09 13:54:42,053 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 13:55:04,811 - INFO - Logging initialize successfully
2025-12-09 13:55:04,917 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 13:55:06,161 - INFO - Built 29000 samples from annotaions
2025-12-09 13:55:06,161 - INFO - Total samples: 29000
2025-12-09 13:55:06,237 - INFO - Built 29000 samples for story 
2025-12-09 13:55:06,372 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 13:56:37,795 - INFO - Logging initialize successfully
2025-12-09 13:56:37,922 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 13:56:39,158 - INFO - Built 29000 samples from annotaions
2025-12-09 13:56:39,161 - INFO - Total samples: 29000
2025-12-09 13:56:39,227 - INFO - Built 29000 samples for story 
2025-12-09 13:56:39,378 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 13:58:46,475 - INFO - Logging initialize successfully
2025-12-09 13:58:46,595 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 13:58:47,844 - INFO - Built 29000 samples from annotaions
2025-12-09 13:58:47,850 - INFO - Total samples: 29000
2025-12-09 13:58:47,914 - INFO - Built 29000 samples for story 
2025-12-09 13:58:48,054 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 13:59:45,519 - INFO - Logging initialize successfully
2025-12-09 13:59:45,653 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 13:59:46,908 - INFO - Built 29000 samples from annotaions
2025-12-09 13:59:46,908 - INFO - Total samples: 29000
2025-12-09 13:59:46,971 - INFO - Built 29000 samples for story 
2025-12-09 13:59:47,115 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 14:52:39,377 - INFO - Logging initialize successfully
2025-12-09 14:52:39,584 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 14:52:41,894 - INFO - Built 29000 samples from annotaions
2025-12-09 14:52:41,894 - INFO - Total samples: 29000
2025-12-09 14:52:42,012 - INFO - Built 29000 samples for story 
2025-12-09 14:52:42,274 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 14:58:58,777 - INFO - Logging initialize successfully
2025-12-09 14:58:58,929 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 14:59:00,420 - INFO - Built 29000 samples from annotaions
2025-12-09 14:59:00,430 - INFO - Total samples: 29000
2025-12-09 14:59:00,508 - INFO - Built 29000 samples for story 
2025-12-09 14:59:00,681 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 15:05:20,168 - INFO - Logging initialize successfully
2025-12-09 15:05:20,305 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 15:05:21,749 - INFO - Built 29000 samples from annotaions
2025-12-09 15:05:21,749 - INFO - Total samples: 29000
2025-12-09 15:05:21,890 - INFO - Built 29000 samples for story 
2025-12-09 15:05:22,039 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 15:06:07,008 - INFO - Logging initialize successfully
2025-12-09 15:06:07,141 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 15:06:08,583 - INFO - Built 29000 samples from annotaions
2025-12-09 15:06:08,595 - INFO - Total samples: 29000
2025-12-09 15:06:08,665 - INFO - Built 29000 samples for story 
2025-12-09 15:06:08,831 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 15:08:03,634 - INFO - Logging initialize successfully
2025-12-09 15:08:03,778 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 15:08:05,260 - INFO - Built 29000 samples from annotaions
2025-12-09 15:08:05,260 - INFO - Total samples: 29000
2025-12-09 15:08:05,331 - INFO - Built 29000 samples for story 
2025-12-09 15:08:05,499 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 15:10:10,298 - INFO - Logging initialize successfully
2025-12-09 15:10:10,439 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 15:10:12,047 - INFO - Built 29000 samples from annotaions
2025-12-09 15:10:12,049 - INFO - Total samples: 29000
2025-12-09 15:10:12,132 - INFO - Built 29000 samples for story 
2025-12-09 15:10:12,313 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 15:11:32,260 - INFO - Logging initialize successfully
2025-12-09 15:11:32,401 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 15:11:33,885 - INFO - Built 29000 samples from annotaions
2025-12-09 15:11:33,885 - INFO - Total samples: 29000
2025-12-09 15:11:33,967 - INFO - Built 29000 samples for story 
2025-12-09 15:11:34,137 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 15:15:10,676 - INFO - Logging initialize successfully
2025-12-09 15:15:10,853 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 15:15:12,444 - INFO - Built 29000 samples from annotaions
2025-12-09 15:15:12,444 - INFO - Total samples: 29000
2025-12-09 15:15:12,525 - INFO - Built 29000 samples for story 
2025-12-09 15:15:12,698 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-09 15:16:53,919 - INFO - Logging initialize successfully
2025-12-09 15:16:54,081 - INFO - Loaded 29000 rows for split='train'.
2025-12-09 15:16:55,656 - INFO - Built 29000 samples from annotaions
2025-12-09 15:16:55,658 - INFO - Total samples: 29000
2025-12-09 15:16:55,736 - INFO - Built 29000 samples for story 
2025-12-09 15:16:55,909 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 11:35:52,865 - INFO - Logging initialize successfully
2025-12-10 11:35:53,023 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 11:35:54,562 - INFO - Built 29000 samples from annotaions
2025-12-10 11:35:54,562 - INFO - Total samples: 29000
2025-12-10 11:35:54,638 - INFO - Built 29000 samples for story 
2025-12-10 11:35:54,812 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 15:03:45,598 - INFO - Logging initialize successfully
2025-12-10 15:03:48,743 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 15:03:50,952 - INFO - Built 29000 samples from annotaions
2025-12-10 15:03:50,954 - INFO - Total samples: 29000
2025-12-10 15:03:51,033 - INFO - Built 29000 samples for story 
2025-12-10 15:03:51,214 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 15:04:45,168 - INFO - Logging initialize successfully
2025-12-10 15:04:47,543 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 15:04:49,707 - INFO - Built 29000 samples from annotaions
2025-12-10 15:04:49,716 - INFO - Total samples: 29000
2025-12-10 15:04:49,801 - INFO - Built 29000 samples for story 
2025-12-10 15:04:49,992 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:32:48,636 - INFO - Logging initialize successfully
2025-12-10 16:32:51,550 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:32:53,154 - INFO - Built 29000 samples from annotaions
2025-12-10 16:32:53,154 - INFO - Total samples: 29000
2025-12-10 16:32:53,245 - INFO - Built 29000 samples for story 
2025-12-10 16:32:53,418 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:34:03,131 - INFO - Logging initialize successfully
2025-12-10 16:34:06,175 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:34:08,064 - INFO - Built 29000 samples from annotaions
2025-12-10 16:34:08,067 - INFO - Total samples: 29000
2025-12-10 16:34:08,173 - INFO - Built 29000 samples for story 
2025-12-10 16:34:08,345 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:34:41,727 - INFO - Logging initialize successfully
2025-12-10 16:34:44,172 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:34:45,882 - INFO - Built 29000 samples from annotaions
2025-12-10 16:34:45,882 - INFO - Total samples: 29000
2025-12-10 16:34:45,962 - INFO - Built 29000 samples for story 
2025-12-10 16:34:46,141 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:44:12,952 - INFO - Logging initialize successfully
2025-12-10 16:44:15,186 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:44:16,622 - INFO - Built 29000 samples from annotaions
2025-12-10 16:44:16,624 - INFO - Total samples: 29000
2025-12-10 16:44:16,688 - INFO - Built 29000 samples for story 
2025-12-10 16:44:16,836 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:44:59,636 - INFO - Logging initialize successfully
2025-12-10 16:45:02,013 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:45:04,886 - INFO - Built 29000 samples from annotaions
2025-12-10 16:45:04,886 - INFO - Total samples: 29000
2025-12-10 16:45:05,032 - INFO - Built 29000 samples for story 
2025-12-10 16:45:05,460 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:47:12,164 - INFO - Logging initialize successfully
2025-12-10 16:47:14,075 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:47:15,477 - INFO - Built 29000 samples from annotaions
2025-12-10 16:47:15,479 - INFO - Total samples: 29000
2025-12-10 16:47:15,544 - INFO - Built 29000 samples for story 
2025-12-10 16:47:15,674 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:50:00,062 - INFO - Logging initialize successfully
2025-12-10 16:50:02,353 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:50:03,702 - INFO - Built 29000 samples from annotaions
2025-12-10 16:50:03,718 - INFO - Total samples: 29000
2025-12-10 16:50:03,782 - INFO - Built 29000 samples for story 
2025-12-10 16:50:03,924 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:53:08,656 - INFO - Logging initialize successfully
2025-12-10 16:53:10,567 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:53:11,942 - INFO - Built 29000 samples from annotaions
2025-12-10 16:53:11,943 - INFO - Total samples: 29000
2025-12-10 16:53:12,009 - INFO - Built 29000 samples for story 
2025-12-10 16:53:12,153 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:54:45,041 - INFO - Logging initialize successfully
2025-12-10 16:54:47,053 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:54:48,532 - INFO - Built 29000 samples from annotaions
2025-12-10 16:54:48,532 - INFO - Total samples: 29000
2025-12-10 16:54:48,597 - INFO - Built 29000 samples for story 
2025-12-10 16:54:48,743 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:56:24,111 - INFO - Logging initialize successfully
2025-12-10 16:56:26,305 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:56:27,716 - INFO - Built 29000 samples from annotaions
2025-12-10 16:56:27,718 - INFO - Total samples: 29000
2025-12-10 16:56:27,783 - INFO - Built 29000 samples for story 
2025-12-10 16:56:27,927 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:57:14,501 - INFO - Logging initialize successfully
2025-12-10 16:57:16,396 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:57:17,804 - INFO - Built 29000 samples from annotaions
2025-12-10 16:57:17,806 - INFO - Total samples: 29000
2025-12-10 16:57:17,871 - INFO - Built 29000 samples for story 
2025-12-10 16:57:18,014 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 16:57:56,309 - INFO - Logging initialize successfully
2025-12-10 16:57:58,571 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 16:57:59,947 - INFO - Built 29000 samples from annotaions
2025-12-10 16:57:59,947 - INFO - Total samples: 29000
2025-12-10 16:58:00,018 - INFO - Built 29000 samples for story 
2025-12-10 16:58:00,155 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 17:10:52,258 - INFO - Logging initialize successfully
2025-12-10 17:10:54,224 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 17:10:55,578 - INFO - Built 29000 samples from annotaions
2025-12-10 17:10:55,578 - INFO - Total samples: 29000
2025-12-10 17:10:55,655 - INFO - Built 29000 samples for story 
2025-12-10 17:10:55,804 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 17:13:12,632 - INFO - Logging initialize successfully
2025-12-10 17:13:14,714 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 17:13:16,088 - INFO - Built 29000 samples from annotaions
2025-12-10 17:13:16,088 - INFO - Total samples: 29000
2025-12-10 17:13:16,157 - INFO - Built 29000 samples for story 
2025-12-10 17:13:16,306 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 17:20:03,152 - INFO - Logging initialize successfully
2025-12-10 17:20:04,906 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 17:20:06,288 - INFO - Built 29000 samples from annotaions
2025-12-10 17:20:06,288 - INFO - Total samples: 29000
2025-12-10 17:20:06,361 - INFO - Built 29000 samples for story 
2025-12-10 17:20:06,504 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-10 17:21:50,651 - INFO - Logging initialize successfully
2025-12-10 17:21:52,915 - INFO - Loaded 29000 rows for split='train'.
2025-12-10 17:21:54,311 - INFO - Built 29000 samples from annotaions
2025-12-10 17:21:54,327 - INFO - Total samples: 29000
2025-12-10 17:21:54,387 - INFO - Built 29000 samples for story 
2025-12-10 17:21:54,534 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 10:14:38,395 - INFO - Logging initialize successfully
2025-12-11 10:14:41,694 - INFO - Loaded 1014 rows for split='val'.
2025-12-11 10:14:41,805 - INFO - Built 1014 samples from annotaions
2025-12-11 10:14:41,805 - INFO - Total samples: 1014
2025-12-11 10:14:41,808 - INFO - Built 1014 samples for story 
2025-12-11 10:14:41,823 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 10:16:24,987 - INFO - Logging initialize successfully
2025-12-11 10:16:27,470 - INFO - Loaded 1014 rows for split='val'.
2025-12-11 10:16:27,546 - INFO - Built 1014 samples from annotaions
2025-12-11 10:16:27,557 - INFO - Total samples: 1014
2025-12-11 10:16:27,561 - INFO - Built 1014 samples for story 
2025-12-11 10:16:27,566 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-11 10:17:15,305 - INFO - Logging initialize successfully
2025-12-11 10:17:17,722 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 10:17:19,384 - INFO - Built 29000 samples from annotaions
2025-12-11 10:17:19,384 - INFO - Total samples: 29000
2025-12-11 10:17:19,465 - INFO - Built 29000 samples for story 
2025-12-11 10:17:19,699 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:17:53,659 - INFO - Logging initialize successfully
2025-12-11 11:17:56,218 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:17:58,186 - INFO - Built 29000 samples from annotaions
2025-12-11 11:17:58,186 - INFO - Total samples: 29000
2025-12-11 11:17:58,273 - INFO - Built 29000 samples for story 
2025-12-11 11:17:58,452 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:18:20,267 - INFO - Logging initialize successfully
2025-12-11 11:18:22,517 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:18:24,200 - INFO - Built 29000 samples from annotaions
2025-12-11 11:18:24,200 - INFO - Total samples: 29000
2025-12-11 11:18:24,281 - INFO - Built 29000 samples for story 
2025-12-11 11:18:24,454 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:20:15,994 - INFO - Logging initialize successfully
2025-12-11 11:20:18,288 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:20:20,039 - INFO - Built 29000 samples from annotaions
2025-12-11 11:20:20,039 - INFO - Total samples: 29000
2025-12-11 11:20:20,122 - INFO - Built 29000 samples for story 
2025-12-11 11:20:20,295 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:20:42,507 - INFO - Logging initialize successfully
2025-12-11 11:20:44,914 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:20:46,624 - INFO - Built 29000 samples from annotaions
2025-12-11 11:20:46,630 - INFO - Total samples: 29000
2025-12-11 11:20:46,704 - INFO - Built 29000 samples for story 
2025-12-11 11:20:46,877 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:21:27,337 - INFO - Logging initialize successfully
2025-12-11 11:21:29,726 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:21:31,673 - INFO - Built 29000 samples from annotaions
2025-12-11 11:21:31,684 - INFO - Total samples: 29000
2025-12-11 11:21:31,761 - INFO - Built 29000 samples for story 
2025-12-11 11:21:31,933 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:22:26,039 - INFO - Logging initialize successfully
2025-12-11 11:22:28,478 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:22:30,145 - INFO - Built 29000 samples from annotaions
2025-12-11 11:22:30,153 - INFO - Total samples: 29000
2025-12-11 11:22:30,228 - INFO - Built 29000 samples for story 
2025-12-11 11:22:30,407 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:22:57,470 - INFO - Logging initialize successfully
2025-12-11 11:22:59,813 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:23:01,637 - INFO - Built 29000 samples from annotaions
2025-12-11 11:23:01,639 - INFO - Total samples: 29000
2025-12-11 11:23:01,717 - INFO - Built 29000 samples for story 
2025-12-11 11:23:01,883 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:25:57,936 - INFO - Logging initialize successfully
2025-12-11 11:26:00,463 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:26:03,110 - INFO - Built 29000 samples from annotaions
2025-12-11 11:26:03,119 - INFO - Total samples: 29000
2025-12-11 11:26:03,244 - INFO - Built 29000 samples for story 
2025-12-11 11:26:03,513 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:27:37,501 - INFO - Logging initialize successfully
2025-12-11 11:27:40,004 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:27:42,665 - INFO - Built 29000 samples from annotaions
2025-12-11 11:27:42,665 - INFO - Total samples: 29000
2025-12-11 11:27:42,787 - INFO - Built 29000 samples for story 
2025-12-11 11:27:43,066 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:29:14,008 - INFO - Logging initialize successfully
2025-12-11 11:29:16,588 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:29:19,200 - INFO - Built 29000 samples from annotaions
2025-12-11 11:29:19,217 - INFO - Total samples: 29000
2025-12-11 11:29:19,337 - INFO - Built 29000 samples for story 
2025-12-11 11:29:19,604 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:35:31,886 - INFO - Logging initialize successfully
2025-12-11 11:35:34,397 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:35:37,095 - INFO - Built 29000 samples from annotaions
2025-12-11 11:35:37,095 - INFO - Total samples: 29000
2025-12-11 11:35:37,237 - INFO - Built 29000 samples for story 
2025-12-11 11:35:37,540 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 11:39:42,968 - INFO - Logging initialize successfully
2025-12-11 11:39:45,495 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 11:39:48,231 - INFO - Built 29000 samples from annotaions
2025-12-11 11:39:48,247 - INFO - Total samples: 29000
2025-12-11 11:39:48,352 - INFO - Built 29000 samples for story 
2025-12-11 11:39:48,616 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 15:14:08,034 - INFO - Logging initialize successfully
2025-12-11 15:14:10,044 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 15:14:11,483 - INFO - Built 29000 samples from annotaions
2025-12-11 15:14:11,483 - INFO - Total samples: 29000
2025-12-11 15:14:11,566 - INFO - Built 29000 samples for story 
2025-12-11 15:14:11,726 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-11 15:17:17,107 - INFO - Logging initialize successfully
2025-12-11 15:17:18,992 - INFO - Loaded 29000 rows for split='train'.
2025-12-11 15:17:20,350 - INFO - Built 29000 samples from annotaions
2025-12-11 15:17:20,352 - INFO - Total samples: 29000
2025-12-11 15:17:20,422 - INFO - Built 29000 samples for story 
2025-12-11 15:17:20,571 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-13 14:49:05,981 - INFO - Loaded 29000 rows for split='train'.
2025-12-13 14:49:06,158 - INFO - Loaded 1014 rows for split='val'.
2025-12-13 14:49:08,177 - INFO - Built 29000 samples from annotaions
2025-12-13 14:49:08,179 - INFO - Total train samples: 29000
2025-12-13 14:49:08,237 - INFO - Built 1014 samples from annotaions
2025-12-13 14:49:08,237 - INFO - Total val samples: 1014
2025-12-13 14:49:08,330 - INFO - Built 29000 samples for story 
2025-12-13 14:49:08,330 - INFO - Built 1014 samples for story 
2025-12-13 14:49:08,542 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-13 14:49:08,552 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-13 14:49:12,497 - INFO - Checkpoint loaded from checkpoints/latest.pth. Resuming at epoch 1. (Scheduler restored: True, Scaler restored: True)
2025-12-13 14:49:12,497 - INFO - Checkpoint loaded from checkpoints/latest.pth. Resuming training from epoch 1, best loss tracked: inf
2025-12-13 14:49:37,228 - INFO - Epoch [1] Batch [0/7250] loss: nan 
2025-12-13 14:49:40,609 - INFO - Epoch [1] Batch [100/7250] loss: nan 
2025-12-13 14:49:43,975 - INFO - Epoch [1] Batch [200/7250] loss: nan 
2025-12-13 14:49:47,320 - INFO - Epoch [1] Batch [300/7250] loss: nan 
2025-12-13 14:53:43,550 - INFO - Logging initialize successfully
2025-12-13 14:53:45,842 - INFO - Loaded 29000 rows for split='train'.
2025-12-13 14:53:45,973 - INFO - Loaded 1014 rows for split='val'.
2025-12-13 14:53:47,370 - INFO - Built 29000 samples from annotaions
2025-12-13 14:53:47,371 - INFO - Total train samples: 29000
2025-12-13 14:53:47,406 - INFO - Built 1014 samples from annotaions
2025-12-13 14:53:47,406 - INFO - Total val samples: 1014
2025-12-13 14:53:47,467 - INFO - Built 29000 samples for story 
2025-12-13 14:53:47,467 - INFO - Built 1014 samples for story 
2025-12-13 14:53:47,606 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-13 14:53:47,626 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-13 14:53:51,844 - INFO - No valid checkpoint found or resume disabled. Starting from scratch.
2025-12-13 14:54:10,694 - INFO - Epoch [1] Batch [0/7250] loss: 10.9993 
2025-12-13 14:54:16,537 - INFO - Epoch [1] Batch [100/7250] loss: 6.3941 
2025-12-13 14:54:22,516 - INFO - Epoch [1] Batch [200/7250] loss: 6.3114 
2025-12-13 14:54:28,429 - INFO - Epoch [1] Batch [300/7250] loss: 5.9478 
2025-12-13 14:54:34,356 - INFO - Epoch [1] Batch [400/7250] loss: 6.3597 
2025-12-13 14:54:40,266 - INFO - Epoch [1] Batch [500/7250] loss: 6.2408 
2025-12-13 14:54:46,287 - INFO - Epoch [1] Batch [600/7250] loss: 5.8349 
2025-12-13 14:54:49,456 - WARNING - NaN/Inf loss detected at batch 662, skipping
2025-12-13 14:54:49,724 - WARNING - NaN/Inf loss detected at batch 668, skipping
2025-12-13 14:54:49,745 - WARNING - NaN/Inf loss detected at batch 669, skipping
2025-12-13 14:54:49,768 - WARNING - NaN/Inf loss detected at batch 670, skipping
2025-12-13 14:54:49,861 - WARNING - NaN/Inf loss detected at batch 673, skipping
2025-12-13 14:54:50,000 - WARNING - NaN/Inf loss detected at batch 677, skipping
2025-12-13 14:54:50,124 - WARNING - NaN/Inf loss detected at batch 680, skipping
2025-12-13 14:54:50,280 - WARNING - NaN/Inf loss detected at batch 684, skipping
2025-12-13 14:54:50,302 - WARNING - NaN/Inf loss detected at batch 685, skipping
2025-12-13 14:54:50,531 - WARNING - NaN/Inf loss detected at batch 691, skipping
2025-12-13 14:54:50,551 - WARNING - NaN/Inf loss detected at batch 692, skipping
2025-12-13 14:54:50,646 - WARNING - NaN/Inf loss detected at batch 695, skipping
2025-12-13 14:54:50,667 - WARNING - NaN/Inf loss detected at batch 696, skipping
2025-12-13 14:54:50,726 - WARNING - NaN/Inf loss detected at batch 698, skipping
2025-12-13 14:54:50,747 - WARNING - NaN/Inf loss detected at batch 699, skipping
2025-12-13 14:54:50,784 - INFO - Epoch [1] Batch [700/7250] loss: 5.9019 
2025-12-13 14:54:50,916 - WARNING - NaN/Inf loss detected at batch 704, skipping
2025-12-13 14:54:51,011 - WARNING - NaN/Inf loss detected at batch 707, skipping
2025-12-13 14:54:51,193 - WARNING - NaN/Inf loss detected at batch 712, skipping
2025-12-13 14:54:51,271 - WARNING - NaN/Inf loss detected at batch 714, skipping
2025-12-13 14:54:51,416 - WARNING - NaN/Inf loss detected at batch 718, skipping
2025-12-13 14:54:51,512 - WARNING - NaN/Inf loss detected at batch 721, skipping
2025-12-13 14:54:51,539 - WARNING - NaN/Inf loss detected at batch 722, skipping
2025-12-13 14:54:51,595 - WARNING - NaN/Inf loss detected at batch 724, skipping
2025-12-13 14:54:51,617 - WARNING - NaN/Inf loss detected at batch 725, skipping
2025-12-13 14:54:51,735 - WARNING - NaN/Inf loss detected at batch 728, skipping
2025-12-13 14:54:51,795 - WARNING - NaN/Inf loss detected at batch 730, skipping
2025-12-13 14:54:51,817 - WARNING - NaN/Inf loss detected at batch 731, skipping
2025-12-13 14:54:51,839 - WARNING - NaN/Inf loss detected at batch 732, skipping
2025-12-13 14:54:51,861 - WARNING - NaN/Inf loss detected at batch 733, skipping
2025-12-13 14:54:51,884 - WARNING - NaN/Inf loss detected at batch 734, skipping
2025-12-13 14:54:51,907 - WARNING - NaN/Inf loss detected at batch 735, skipping
2025-12-13 14:54:51,927 - WARNING - NaN/Inf loss detected at batch 736, skipping
2025-12-13 14:54:51,949 - WARNING - NaN/Inf loss detected at batch 737, skipping
2025-12-13 14:54:51,969 - WARNING - NaN/Inf loss detected at batch 738, skipping
2025-12-13 14:54:51,990 - WARNING - NaN/Inf loss detected at batch 739, skipping
2025-12-13 14:54:52,013 - WARNING - NaN/Inf loss detected at batch 740, skipping
2025-12-13 14:54:52,036 - WARNING - NaN/Inf loss detected at batch 741, skipping
2025-12-13 14:54:52,059 - WARNING - NaN/Inf loss detected at batch 742, skipping
2025-12-13 14:54:52,122 - WARNING - NaN/Inf loss detected at batch 744, skipping
2025-12-13 14:54:52,183 - WARNING - NaN/Inf loss detected at batch 746, skipping
2025-12-13 14:54:52,206 - WARNING - NaN/Inf loss detected at batch 747, skipping
2025-12-13 14:54:52,425 - WARNING - NaN/Inf loss detected at batch 752, skipping
2025-12-13 14:54:52,448 - WARNING - NaN/Inf loss detected at batch 753, skipping
2025-12-13 14:54:52,473 - WARNING - NaN/Inf loss detected at batch 754, skipping
2025-12-13 14:54:52,496 - WARNING - NaN/Inf loss detected at batch 755, skipping
2025-12-13 14:54:52,519 - WARNING - NaN/Inf loss detected at batch 756, skipping
2025-12-13 14:54:52,540 - WARNING - NaN/Inf loss detected at batch 757, skipping
2025-12-13 14:54:52,563 - WARNING - NaN/Inf loss detected at batch 758, skipping
2025-12-13 14:54:52,585 - WARNING - NaN/Inf loss detected at batch 759, skipping
2025-12-13 14:54:52,607 - WARNING - NaN/Inf loss detected at batch 760, skipping
2025-12-13 14:54:52,630 - WARNING - NaN/Inf loss detected at batch 761, skipping
2025-12-13 14:54:52,651 - WARNING - NaN/Inf loss detected at batch 762, skipping
2025-12-13 14:54:52,715 - WARNING - NaN/Inf loss detected at batch 764, skipping
2025-12-13 14:54:52,741 - WARNING - NaN/Inf loss detected at batch 765, skipping
2025-12-13 17:11:55,938 - INFO - Epoch [1] Batch [0/254] loss: 1.4289 
2025-12-13 17:11:56,271 - INFO - Epoch [1] Batch [10/254] loss: 1.4223 
2025-12-13 17:11:56,463 - INFO - Epoch [1] Batch [20/254] loss: 1.4468 
2025-12-13 17:11:56,675 - INFO - Epoch [1] Batch [30/254] loss: 1.6530 
2025-12-13 17:11:56,860 - INFO - Epoch [1] Batch [40/254] loss: 1.5636 
2025-12-13 17:11:57,056 - INFO - Epoch [1] Batch [50/254] loss: 1.4243 
2025-12-13 17:11:57,248 - INFO - Epoch [1] Batch [60/254] loss: 1.4727 
2025-12-13 17:11:57,445 - INFO - Epoch [1] Batch [70/254] loss: 1.4719 
2025-12-13 17:11:57,641 - INFO - Epoch [1] Batch [80/254] loss: 1.4177 
2025-12-13 17:11:57,839 - INFO - Epoch [1] Batch [90/254] loss: 1.4174 
2025-12-13 17:11:58,044 - INFO - Epoch [1] Batch [100/254] loss: 1.4993 
2025-12-13 17:11:58,245 - INFO - Epoch [1] Batch [110/254] loss: 1.4862 
2025-12-13 17:11:58,456 - INFO - Epoch [1] Batch [120/254] loss: 1.6136 
2025-12-13 17:11:58,644 - INFO - Epoch [1] Batch [130/254] loss: 1.5060 
2025-12-13 17:11:58,835 - INFO - Epoch [1] Batch [140/254] loss: 1.6773 
2025-12-13 17:11:59,035 - INFO - Epoch [1] Batch [150/254] loss: 1.4372 
2025-12-13 17:11:59,233 - INFO - Epoch [1] Batch [160/254] loss: 1.7358 
2025-12-13 17:11:59,418 - INFO - Epoch [1] Batch [170/254] loss: 1.5561 
2025-12-13 17:11:59,615 - INFO - Epoch [1] Batch [180/254] loss: 1.4568 
2025-12-13 17:11:59,801 - INFO - Epoch [1] Batch [190/254] loss: 1.5316 
2025-12-13 17:12:00,008 - INFO - Epoch [1] Batch [200/254] loss: 1.4948 
2025-12-13 17:12:00,213 - INFO - Epoch [1] Batch [210/254] loss: 1.5469 
2025-12-13 17:12:00,409 - INFO - Epoch [1] Batch [220/254] loss: 1.6692 
2025-12-13 17:12:00,609 - INFO - Epoch [1] Batch [230/254] loss: 1.6189 
2025-12-13 17:12:00,832 - INFO - Epoch [1] Batch [240/254] loss: 1.5010 
2025-12-13 17:12:01,028 - INFO - Epoch [1] Batch [250/254] loss: 1.5679 
2025-12-13 17:12:01,789 - INFO - Epoch: [1/10]Train loss: 1.7083 | Val loss: 1.5089
2025-12-13 17:12:01,789 - INFO - Validation loss improved from inf to 1.5089 Saving Best model.
2025-12-13 17:12:02,603 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 1)
2025-12-13 17:12:03,423 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 1)
2025-12-13 17:12:21,480 - INFO - Epoch [2] Batch [0/7250] loss: 1.4719 
2025-12-13 17:12:27,457 - INFO - Epoch [2] Batch [100/7250] loss: 1.4859 
2025-12-13 17:12:34,393 - INFO - Epoch [2] Batch [200/7250] loss: 1.4424 
2025-12-13 17:12:41,406 - INFO - Epoch [2] Batch [300/7250] loss: 1.4178 
2025-12-13 17:12:48,556 - INFO - Epoch [2] Batch [400/7250] loss: 1.5291 
2025-12-13 17:12:55,011 - INFO - Epoch [2] Batch [500/7250] loss: 1.4299 
2025-12-13 17:13:01,155 - INFO - Epoch [2] Batch [600/7250] loss: 1.4163 
2025-12-13 17:13:08,113 - INFO - Epoch [2] Batch [700/7250] loss: 1.4191 
2025-12-13 17:13:15,149 - INFO - Epoch [2] Batch [800/7250] loss: 1.4766 
2025-12-13 17:13:22,428 - INFO - Epoch [2] Batch [900/7250] loss: 1.4632 
2025-12-13 17:13:29,428 - INFO - Epoch [2] Batch [1000/7250] loss: 1.4742 
2025-12-13 17:13:36,399 - INFO - Epoch [2] Batch [1100/7250] loss: 1.4766 
2025-12-13 17:13:43,343 - INFO - Epoch [2] Batch [1200/7250] loss: 1.5231 
2025-12-13 17:13:50,423 - INFO - Epoch [2] Batch [1300/7250] loss: 1.5584 
2025-12-13 17:13:57,373 - INFO - Epoch [2] Batch [1400/7250] loss: 1.5687 
2025-12-13 17:14:04,291 - INFO - Epoch [2] Batch [1500/7250] loss: 1.4487 
2025-12-13 17:14:11,268 - INFO - Epoch [2] Batch [1600/7250] loss: 1.4507 
2025-12-13 17:14:18,517 - INFO - Epoch [2] Batch [1700/7250] loss: 1.4839 
2025-12-13 17:14:25,279 - INFO - Epoch [2] Batch [1800/7250] loss: 1.4156 
2025-12-13 17:14:31,770 - INFO - Epoch [2] Batch [1900/7250] loss: 1.4906 
2025-12-13 17:14:38,169 - INFO - Epoch [2] Batch [2000/7250] loss: 1.4802 
2025-12-13 17:14:45,408 - INFO - Epoch [2] Batch [2100/7250] loss: 1.4181 
2025-12-13 17:14:52,602 - INFO - Epoch [2] Batch [2200/7250] loss: 1.4148 
2025-12-13 17:14:59,650 - INFO - Epoch [2] Batch [2300/7250] loss: 1.4165 
2025-12-13 17:15:06,590 - INFO - Epoch [2] Batch [2400/7250] loss: 1.4460 
2025-12-13 17:15:13,619 - INFO - Epoch [2] Batch [2500/7250] loss: 1.4608 
2025-12-13 17:15:20,639 - INFO - Epoch [2] Batch [2600/7250] loss: 1.4206 
2025-12-13 17:15:27,535 - INFO - Epoch [2] Batch [2700/7250] loss: 1.4926 
2025-12-13 17:15:34,452 - INFO - Epoch [2] Batch [2800/7250] loss: 1.4270 
2025-12-13 17:15:41,667 - INFO - Epoch [2] Batch [2900/7250] loss: 1.4733 
2025-12-13 17:15:48,672 - INFO - Epoch [2] Batch [3000/7250] loss: 1.4658 
2025-12-13 17:15:55,714 - INFO - Epoch [2] Batch [3100/7250] loss: 1.4498 
2025-12-13 17:16:02,528 - INFO - Epoch [2] Batch [3200/7250] loss: 1.4580 
2025-12-13 17:16:09,499 - INFO - Epoch [2] Batch [3300/7250] loss: 1.4320 
2025-12-13 17:16:16,570 - INFO - Epoch [2] Batch [3400/7250] loss: 1.4170 
2025-12-13 17:16:23,511 - INFO - Epoch [2] Batch [3500/7250] loss: 1.4985 
2025-12-13 17:16:30,463 - INFO - Epoch [2] Batch [3600/7250] loss: 1.4545 
2025-12-13 17:16:37,413 - INFO - Epoch [2] Batch [3700/7250] loss: 1.5065 
2025-12-13 17:16:44,501 - INFO - Epoch [2] Batch [3800/7250] loss: 1.4795 
2025-12-13 17:16:51,476 - INFO - Epoch [2] Batch [3900/7250] loss: 1.5246 
2025-12-13 17:16:58,536 - INFO - Epoch [2] Batch [4000/7250] loss: 1.6052 
2025-12-13 17:17:05,365 - INFO - Epoch [2] Batch [4100/7250] loss: 1.4142 
2025-12-13 17:17:12,278 - INFO - Epoch [2] Batch [4200/7250] loss: 1.4132 
2025-12-13 17:17:19,374 - INFO - Epoch [2] Batch [4300/7250] loss: 1.7327 
2025-12-13 17:17:26,574 - INFO - Epoch [2] Batch [4400/7250] loss: 1.4155 
2025-12-13 17:17:34,094 - INFO - Epoch [2] Batch [4500/7250] loss: 1.4614 
2025-12-13 17:17:41,680 - INFO - Epoch [2] Batch [4600/7250] loss: 1.4678 
2025-12-13 17:17:49,055 - INFO - Epoch [2] Batch [4700/7250] loss: 1.4135 
2025-12-13 17:17:56,360 - INFO - Epoch [2] Batch [4800/7250] loss: 1.5475 
2025-12-13 17:18:03,560 - INFO - Epoch [2] Batch [4900/7250] loss: 1.4992 
2025-12-13 17:18:10,826 - INFO - Epoch [2] Batch [5000/7250] loss: 1.4146 
2025-12-13 17:18:18,090 - INFO - Epoch [2] Batch [5100/7250] loss: 1.4466 
2025-12-13 17:18:25,125 - INFO - Epoch [2] Batch [5200/7250] loss: 1.4875 
2025-12-13 17:18:32,233 - INFO - Epoch [2] Batch [5300/7250] loss: 1.5148 
2025-12-13 17:18:39,344 - INFO - Epoch [2] Batch [5400/7250] loss: 1.4772 
2025-12-13 17:18:45,615 - INFO - Epoch [2] Batch [5500/7250] loss: 1.5564 
2025-12-13 17:18:52,237 - INFO - Epoch [2] Batch [5600/7250] loss: 1.4155 
2025-12-13 17:18:58,861 - INFO - Epoch [2] Batch [5700/7250] loss: 1.4707 
2025-12-13 17:19:05,755 - INFO - Epoch [2] Batch [5800/7250] loss: 1.6158 
2025-12-13 17:19:13,487 - INFO - Epoch [2] Batch [5900/7250] loss: 1.4156 
2025-12-13 17:19:20,665 - INFO - Epoch [2] Batch [6000/7250] loss: 1.5462 
2025-12-13 17:19:27,992 - INFO - Epoch [2] Batch [6100/7250] loss: 1.4129 
2025-12-13 17:19:35,165 - INFO - Epoch [2] Batch [6200/7250] loss: 1.4798 
2025-12-13 17:19:41,706 - INFO - Epoch [2] Batch [6300/7250] loss: 1.4493 
2025-12-13 17:19:48,550 - INFO - Epoch [2] Batch [6400/7250] loss: 1.4152 
2025-12-13 17:19:55,683 - INFO - Epoch [2] Batch [6500/7250] loss: 1.4127 
2025-12-13 17:20:02,488 - INFO - Epoch [2] Batch [6600/7250] loss: 1.4991 
2025-12-13 17:20:09,419 - INFO - Epoch [2] Batch [6700/7250] loss: 1.4751 
2025-12-13 17:20:16,403 - INFO - Epoch [2] Batch [6800/7250] loss: 1.4147 
2025-12-13 17:20:23,418 - INFO - Epoch [2] Batch [6900/7250] loss: 1.4520 
2025-12-13 17:20:30,394 - INFO - Epoch [2] Batch [7000/7250] loss: 1.4282 
2025-12-13 17:20:37,438 - INFO - Epoch [2] Batch [7100/7250] loss: 1.4275 
2025-12-13 17:20:44,246 - INFO - Epoch [2] Batch [7200/7250] loss: 1.5945 
2025-12-13 17:21:12,469 - INFO - Epoch [2] Batch [0/254] loss: 1.4187 
2025-12-13 17:21:12,802 - INFO - Epoch [2] Batch [10/254] loss: 1.4196 
2025-12-13 17:21:13,069 - INFO - Epoch [2] Batch [20/254] loss: 1.4202 
2025-12-13 17:21:13,342 - INFO - Epoch [2] Batch [30/254] loss: 1.5707 
2025-12-13 17:21:13,598 - INFO - Epoch [2] Batch [40/254] loss: 1.5608 
2025-12-13 17:21:13,859 - INFO - Epoch [2] Batch [50/254] loss: 1.4169 
2025-12-13 17:21:14,115 - INFO - Epoch [2] Batch [60/254] loss: 1.4185 
2025-12-13 17:21:14,373 - INFO - Epoch [2] Batch [70/254] loss: 1.4175 
2025-12-13 17:21:14,634 - INFO - Epoch [2] Batch [80/254] loss: 1.4157 
2025-12-13 17:21:14,883 - INFO - Epoch [2] Batch [90/254] loss: 1.4162 
2025-12-13 17:21:15,133 - INFO - Epoch [2] Batch [100/254] loss: 1.4717 
2025-12-13 17:21:15,386 - INFO - Epoch [2] Batch [110/254] loss: 1.4630 
2025-12-13 17:21:15,634 - INFO - Epoch [2] Batch [120/254] loss: 1.4799 
2025-12-13 17:21:15,884 - INFO - Epoch [2] Batch [130/254] loss: 1.4763 
2025-12-13 17:21:16,137 - INFO - Epoch [2] Batch [140/254] loss: 1.6307 
2025-12-13 17:21:16,390 - INFO - Epoch [2] Batch [150/254] loss: 1.4192 
2025-12-13 17:21:16,643 - INFO - Epoch [2] Batch [160/254] loss: 1.6771 
2025-12-13 17:21:16,902 - INFO - Epoch [2] Batch [170/254] loss: 1.5031 
2025-12-13 17:21:17,156 - INFO - Epoch [2] Batch [180/254] loss: 1.4202 
2025-12-13 17:21:17,405 - INFO - Epoch [2] Batch [190/254] loss: 1.5014 
2025-12-13 17:21:17,662 - INFO - Epoch [2] Batch [200/254] loss: 1.4628 
2025-12-13 17:21:17,918 - INFO - Epoch [2] Batch [210/254] loss: 1.4874 
2025-12-13 17:21:18,185 - INFO - Epoch [2] Batch [220/254] loss: 1.5968 
2025-12-13 17:21:18,439 - INFO - Epoch [2] Batch [230/254] loss: 1.6021 
2025-12-13 17:21:18,695 - INFO - Epoch [2] Batch [240/254] loss: 1.4889 
2025-12-13 17:21:18,942 - INFO - Epoch [2] Batch [250/254] loss: 1.4885 
2025-12-13 17:21:19,866 - INFO - Epoch: [2/10]Train loss: 1.4722 | Val loss: 1.4782
2025-12-13 17:21:19,866 - INFO - Validation loss improved from 1.5089 to 1.4782 Saving Best model.
2025-12-13 17:21:20,941 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 2)
2025-12-13 17:21:21,886 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 2)
2025-12-13 17:21:39,939 - INFO - Epoch [3] Batch [0/7250] loss: 1.4288 
2025-12-13 17:21:46,198 - INFO - Epoch [3] Batch [100/7250] loss: 1.4167 
2025-12-13 17:21:52,904 - INFO - Epoch [3] Batch [200/7250] loss: 1.4602 
2025-12-13 17:21:59,022 - INFO - Epoch [3] Batch [300/7250] loss: 1.4405 
2025-12-13 17:22:05,087 - INFO - Epoch [3] Batch [400/7250] loss: 1.4905 
2025-12-13 17:22:11,116 - INFO - Epoch [3] Batch [500/7250] loss: 1.4135 
2025-12-13 17:22:17,116 - INFO - Epoch [3] Batch [600/7250] loss: 1.4129 
2025-12-13 17:22:23,148 - INFO - Epoch [3] Batch [700/7250] loss: 1.4219 
2025-12-13 17:22:30,078 - INFO - Epoch [3] Batch [800/7250] loss: 1.4336 
2025-12-13 17:22:36,155 - INFO - Epoch [3] Batch [900/7250] loss: 1.4128 
2025-12-13 17:22:42,191 - INFO - Epoch [3] Batch [1000/7250] loss: 1.4127 
2025-12-13 17:22:48,261 - INFO - Epoch [3] Batch [1100/7250] loss: 1.4537 
2025-12-13 17:22:54,282 - INFO - Epoch [3] Batch [1200/7250] loss: 1.4947 
2025-12-13 17:23:00,416 - INFO - Epoch [3] Batch [1300/7250] loss: 1.4148 
2025-12-13 17:23:06,436 - INFO - Epoch [3] Batch [1400/7250] loss: 1.4551 
2025-12-13 17:23:12,519 - INFO - Epoch [3] Batch [1500/7250] loss: 1.4534 
2025-12-13 17:23:18,684 - INFO - Epoch [3] Batch [1600/7250] loss: 1.4527 
2025-12-13 17:23:24,929 - INFO - Epoch [3] Batch [1700/7250] loss: 1.4177 
2025-12-13 17:23:31,179 - INFO - Epoch [3] Batch [1800/7250] loss: 1.4842 
2025-12-13 17:23:37,477 - INFO - Epoch [3] Batch [1900/7250] loss: 1.4214 
2025-12-13 17:23:43,712 - INFO - Epoch [3] Batch [2000/7250] loss: 1.4256 
2025-12-13 17:23:50,584 - INFO - Epoch [3] Batch [2100/7250] loss: 1.4165 
2025-12-13 17:23:57,296 - INFO - Epoch [3] Batch [2200/7250] loss: 1.4946 
2025-12-13 17:24:03,973 - INFO - Epoch [3] Batch [2300/7250] loss: 1.4199 
2025-12-13 17:24:10,361 - INFO - Epoch [3] Batch [2400/7250] loss: 1.4160 
2025-12-13 17:24:16,709 - INFO - Epoch [3] Batch [2500/7250] loss: 1.5322 
2025-12-13 17:24:23,048 - INFO - Epoch [3] Batch [2600/7250] loss: 1.4157 
2025-12-13 17:24:29,198 - INFO - Epoch [3] Batch [2700/7250] loss: 1.4297 
2025-12-13 17:24:35,426 - INFO - Epoch [3] Batch [2800/7250] loss: 1.4373 
2025-12-13 17:24:41,643 - INFO - Epoch [3] Batch [2900/7250] loss: 1.4136 
2025-12-13 17:26:43,922 - INFO - Logging initialize successfully
2025-12-13 17:26:46,701 - INFO - Loaded 29000 rows for split='train'.
2025-12-13 17:26:46,803 - INFO - Loaded 1014 rows for split='val'.
2025-12-13 17:26:48,188 - INFO - Built 29000 samples from annotaions
2025-12-13 17:26:48,194 - INFO - Total train samples: 29000
2025-12-13 17:26:48,231 - INFO - Built 1014 samples from annotaions
2025-12-13 17:26:48,232 - INFO - Total val samples: 1014
2025-12-13 17:26:48,287 - INFO - Built 29000 samples for story 
2025-12-13 17:26:48,298 - INFO - Built 1014 samples for story 
2025-12-13 17:26:48,446 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-13 17:26:48,453 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-13 17:26:52,159 - INFO - Checkpoint loaded from checkpoints/latest.pth. Resuming at epoch 2. (Scheduler restored: True, Scaler restored: True)
2025-12-13 17:26:52,159 - INFO - Checkpoint loaded from checkpoints/latest.pth. Resuming training from epoch 2, best loss tracked: inf
2025-12-13 17:27:10,064 - INFO - Epoch [2] Batch [0/7250] loss: 1.4865 
2025-12-13 17:27:16,072 - INFO - Epoch [2] Batch [100/7250] loss: 1.4259 
2025-12-13 17:27:22,082 - INFO - Epoch [2] Batch [200/7250] loss: 1.4134 
2025-12-13 17:27:28,233 - INFO - Epoch [2] Batch [300/7250] loss: 1.4144 
2025-12-13 17:27:34,476 - INFO - Epoch [2] Batch [400/7250] loss: 1.4169 
2025-12-13 17:27:40,896 - INFO - Epoch [2] Batch [500/7250] loss: 1.4527 
2025-12-13 17:27:47,066 - INFO - Epoch [2] Batch [600/7250] loss: 1.4558 
2025-12-13 17:27:53,424 - INFO - Epoch [2] Batch [700/7250] loss: 1.4237 
2025-12-13 17:27:59,831 - INFO - Epoch [2] Batch [800/7250] loss: 1.4814 
2025-12-13 17:28:06,093 - INFO - Epoch [2] Batch [900/7250] loss: 1.6669 
2025-12-13 17:28:12,426 - INFO - Epoch [2] Batch [1000/7250] loss: 1.4690 
2025-12-13 17:28:18,850 - INFO - Epoch [2] Batch [1100/7250] loss: 1.5909 
2025-12-13 17:28:25,080 - INFO - Epoch [2] Batch [1200/7250] loss: 1.4129 
2025-12-13 17:28:31,618 - INFO - Epoch [2] Batch [1300/7250] loss: 1.4132 
2025-12-13 17:28:37,964 - INFO - Epoch [2] Batch [1400/7250] loss: 1.4124 
2025-12-13 17:28:44,198 - INFO - Epoch [2] Batch [1500/7250] loss: 1.5799 
2025-12-13 17:28:50,547 - INFO - Epoch [2] Batch [1600/7250] loss: 1.4540 
2025-12-13 17:28:56,695 - INFO - Epoch [2] Batch [1700/7250] loss: 1.4116 
2025-12-13 17:29:02,877 - INFO - Epoch [2] Batch [1800/7250] loss: 1.4154 
2025-12-13 17:29:09,284 - INFO - Epoch [2] Batch [1900/7250] loss: 1.4135 
2025-12-13 17:29:15,571 - INFO - Epoch [2] Batch [2000/7250] loss: 1.4123 
2025-12-13 17:29:21,940 - INFO - Epoch [2] Batch [2100/7250] loss: 1.4148 
2025-12-13 17:29:28,394 - INFO - Epoch [2] Batch [2200/7250] loss: 1.4890 
2025-12-13 17:29:35,621 - INFO - Epoch [2] Batch [2300/7250] loss: 1.4949 
2025-12-13 17:29:42,826 - INFO - Epoch [2] Batch [2400/7250] loss: 1.4145 
2025-12-13 17:29:50,033 - INFO - Epoch [2] Batch [2500/7250] loss: 1.4861 
2025-12-13 17:29:57,173 - INFO - Epoch [2] Batch [2600/7250] loss: 1.4134 
2025-12-13 17:30:04,367 - INFO - Epoch [2] Batch [2700/7250] loss: 1.4624 
2025-12-13 17:30:11,756 - INFO - Epoch [2] Batch [2800/7250] loss: 1.4131 
2025-12-13 17:30:18,501 - INFO - Epoch [2] Batch [2900/7250] loss: 1.5316 
2025-12-13 17:30:25,014 - INFO - Epoch [2] Batch [3000/7250] loss: 1.4143 
2025-12-13 17:30:32,234 - INFO - Epoch [2] Batch [3100/7250] loss: 1.4113 
2025-12-13 17:30:40,107 - INFO - Epoch [2] Batch [3200/7250] loss: 1.4153 
2025-12-13 17:30:47,863 - INFO - Epoch [2] Batch [3300/7250] loss: 1.4621 
2025-12-13 17:30:55,575 - INFO - Epoch [2] Batch [3400/7250] loss: 1.4128 
2025-12-13 17:31:02,818 - INFO - Epoch [2] Batch [3500/7250] loss: 1.4872 
2025-12-13 17:31:10,120 - INFO - Epoch [2] Batch [3600/7250] loss: 1.5323 
2025-12-13 17:31:17,399 - INFO - Epoch [2] Batch [3700/7250] loss: 1.4149 
2025-12-13 17:31:24,617 - INFO - Epoch [2] Batch [3800/7250] loss: 1.4955 
2025-12-13 17:31:31,913 - INFO - Epoch [2] Batch [3900/7250] loss: 1.4132 
2025-12-13 17:31:39,209 - INFO - Epoch [2] Batch [4000/7250] loss: 1.5800 
2025-12-13 17:31:46,576 - INFO - Epoch [2] Batch [4100/7250] loss: 1.4508 
2025-12-13 17:31:53,936 - INFO - Epoch [2] Batch [4200/7250] loss: 1.4381 
2025-12-13 17:32:01,275 - INFO - Epoch [2] Batch [4300/7250] loss: 1.4139 
2025-12-13 17:32:07,785 - INFO - Epoch [2] Batch [4400/7250] loss: 1.4133 
2025-12-13 17:32:14,224 - INFO - Epoch [2] Batch [4500/7250] loss: 1.4134 
2025-12-13 17:32:21,539 - INFO - Epoch [2] Batch [4600/7250] loss: 1.4215 
2025-12-13 17:32:28,819 - INFO - Epoch [2] Batch [4700/7250] loss: 1.4114 
2025-12-13 17:32:36,001 - INFO - Epoch [2] Batch [4800/7250] loss: 1.6106 
2025-12-13 17:32:42,733 - INFO - Epoch [2] Batch [4900/7250] loss: 1.4166 
2025-12-13 17:32:48,909 - INFO - Epoch [2] Batch [5000/7250] loss: 1.4793 
2025-12-13 17:32:55,090 - INFO - Epoch [2] Batch [5100/7250] loss: 1.4128 
2025-12-13 17:33:01,356 - INFO - Epoch [2] Batch [5200/7250] loss: 1.4532 
2025-12-13 17:33:07,541 - INFO - Epoch [2] Batch [5300/7250] loss: 1.4112 
2025-12-13 17:33:13,734 - INFO - Epoch [2] Batch [5400/7250] loss: 1.4904 
2025-12-13 17:33:19,981 - INFO - Epoch [2] Batch [5500/7250] loss: 1.5761 
2025-12-13 17:33:26,314 - INFO - Epoch [2] Batch [5600/7250] loss: 1.4156 
2025-12-13 17:33:32,549 - INFO - Epoch [2] Batch [5700/7250] loss: 1.5210 
2025-12-13 17:33:38,941 - INFO - Epoch [2] Batch [5800/7250] loss: 1.4140 
2025-12-13 17:33:45,307 - INFO - Epoch [2] Batch [5900/7250] loss: 1.4167 
2025-12-13 17:33:51,611 - INFO - Epoch [2] Batch [6000/7250] loss: 1.4117 
2025-12-13 17:33:57,921 - INFO - Epoch [2] Batch [6100/7250] loss: 1.4155 
2025-12-13 17:34:04,133 - INFO - Epoch [2] Batch [6200/7250] loss: 1.4117 
2025-12-13 17:34:10,361 - INFO - Epoch [2] Batch [6300/7250] loss: 1.5766 
2025-12-13 17:34:16,622 - INFO - Epoch [2] Batch [6400/7250] loss: 1.4111 
2025-12-13 17:34:22,864 - INFO - Epoch [2] Batch [6500/7250] loss: 1.6682 
2025-12-13 17:34:29,084 - INFO - Epoch [2] Batch [6600/7250] loss: 1.4774 
2025-12-13 17:34:35,388 - INFO - Epoch [2] Batch [6700/7250] loss: 1.4342 
2025-12-13 17:34:41,704 - INFO - Epoch [2] Batch [6800/7250] loss: 1.4122 
2025-12-13 17:34:48,164 - INFO - Epoch [2] Batch [6900/7250] loss: 1.5022 
2025-12-13 17:34:54,656 - INFO - Epoch [2] Batch [7000/7250] loss: 1.4187 
2025-12-13 17:35:01,127 - INFO - Epoch [2] Batch [7100/7250] loss: 1.4145 
2025-12-13 17:35:07,576 - INFO - Epoch [2] Batch [7200/7250] loss: 1.4139 
2025-12-13 17:35:30,866 - INFO - Epoch [2] Batch [0/254] loss: 1.4164 
2025-12-13 17:35:31,089 - INFO - Epoch [2] Batch [10/254] loss: 1.4147 
2025-12-13 17:35:31,296 - INFO - Epoch [2] Batch [20/254] loss: 1.4135 
2025-12-13 17:35:31,512 - INFO - Epoch [2] Batch [30/254] loss: 1.4160 
2025-12-13 17:35:31,715 - INFO - Epoch [2] Batch [40/254] loss: 1.5644 
2025-12-13 17:35:31,920 - INFO - Epoch [2] Batch [50/254] loss: 1.4160 
2025-12-13 17:35:32,138 - INFO - Epoch [2] Batch [60/254] loss: 1.8417 
2025-12-13 17:35:32,345 - INFO - Epoch [2] Batch [70/254] loss: 1.4303 
2025-12-13 17:35:32,553 - INFO - Epoch [2] Batch [80/254] loss: 1.4169 
2025-12-13 17:35:32,764 - INFO - Epoch [2] Batch [90/254] loss: 1.4154 
2025-12-13 17:35:32,962 - INFO - Epoch [2] Batch [100/254] loss: 1.5172 
2025-12-13 17:35:33,167 - INFO - Epoch [2] Batch [110/254] loss: 1.4154 
2025-12-13 17:35:33,427 - INFO - Epoch [2] Batch [120/254] loss: 1.4175 
2025-12-13 17:35:33,685 - INFO - Epoch [2] Batch [130/254] loss: 1.4632 
2025-12-13 17:35:33,920 - INFO - Epoch [2] Batch [140/254] loss: 1.4165 
2025-12-13 17:35:34,129 - INFO - Epoch [2] Batch [150/254] loss: 1.4174 
2025-12-13 17:35:34,332 - INFO - Epoch [2] Batch [160/254] loss: 1.4181 
2025-12-13 17:35:34,545 - INFO - Epoch [2] Batch [170/254] loss: 1.4942 
2025-12-13 17:35:34,761 - INFO - Epoch [2] Batch [180/254] loss: 1.4179 
2025-12-13 17:35:34,968 - INFO - Epoch [2] Batch [190/254] loss: 1.4181 
2025-12-13 17:35:35,171 - INFO - Epoch [2] Batch [200/254] loss: 1.4809 
2025-12-13 17:35:35,373 - INFO - Epoch [2] Batch [210/254] loss: 1.4898 
2025-12-13 17:35:35,572 - INFO - Epoch [2] Batch [220/254] loss: 1.4418 
2025-12-13 17:35:35,771 - INFO - Epoch [2] Batch [230/254] loss: 1.5498 
2025-12-13 17:35:35,976 - INFO - Epoch [2] Batch [240/254] loss: 1.4165 
2025-12-13 17:35:36,184 - INFO - Epoch [2] Batch [250/254] loss: 1.4624 
2025-12-13 17:35:36,957 - INFO - Epoch: [2/10]Train loss: 1.4621 | Val loss: 1.4626
2025-12-13 17:35:38,758 - INFO - Epoch 2 Generated Story: markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings markings
2025-12-13 17:35:38,758 - INFO - Validation loss improved from inf to 1.4626 Saving Best model.
2025-12-13 17:35:39,577 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 2)
2025-12-13 17:35:40,376 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 2)
2025-12-13 17:35:58,123 - INFO - Epoch [3] Batch [0/7250] loss: 1.4123 
2025-12-13 17:37:36,981 - INFO - Logging initialize successfully
2025-12-13 17:37:39,294 - INFO - Loaded 29000 rows for split='train'.
2025-12-13 17:37:39,410 - INFO - Loaded 1014 rows for split='val'.
2025-12-13 17:37:40,790 - INFO - Built 29000 samples from annotaions
2025-12-13 17:37:40,790 - INFO - Total train samples: 29000
2025-12-13 17:37:40,836 - INFO - Built 1014 samples from annotaions
2025-12-13 17:37:40,836 - INFO - Total val samples: 1014
2025-12-13 17:37:40,888 - INFO - Built 29000 samples for story 
2025-12-13 17:37:40,904 - INFO - Built 1014 samples for story 
2025-12-13 17:37:41,045 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-13 17:37:41,045 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-13 17:37:44,904 - INFO - Checkpoint loaded from checkpoints/latest.pth. Resuming at epoch 2. (Scheduler restored: True, Scaler restored: True)
2025-12-13 17:37:44,904 - INFO - Checkpoint loaded from checkpoints/latest.pth. Resuming training from epoch 2, best loss tracked: inf
2025-12-13 17:38:02,921 - INFO - Epoch [2] Batch [0/7250] loss: 1.4127 
2025-12-13 17:38:18,228 - INFO - Epoch [2] Batch [250/7250] loss: 1.4765 
2025-12-13 17:38:33,972 - INFO - Epoch [2] Batch [500/7250] loss: 1.4120 
2025-12-13 17:38:49,249 - INFO - Epoch [2] Batch [750/7250] loss: 1.4124 
2025-12-13 17:39:04,576 - INFO - Epoch [2] Batch [1000/7250] loss: 1.4131 
2025-12-13 17:39:20,327 - INFO - Epoch [2] Batch [1250/7250] loss: 1.4468 
2025-12-13 17:39:38,204 - INFO - Epoch [2] Batch [1500/7250] loss: 1.4114 
2025-12-13 17:39:56,516 - INFO - Epoch [2] Batch [1750/7250] loss: 1.4786 
2025-12-13 17:40:14,837 - INFO - Epoch [2] Batch [2000/7250] loss: 1.4120 
2025-12-13 17:40:32,836 - INFO - Epoch [2] Batch [2250/7250] loss: 1.4551 
2025-12-13 17:40:50,655 - INFO - Epoch [2] Batch [2500/7250] loss: 1.5294 
2025-12-13 17:41:08,909 - INFO - Epoch [2] Batch [2750/7250] loss: 1.4838 
2025-12-13 17:41:26,351 - INFO - Epoch [2] Batch [3000/7250] loss: 1.4115 
2025-12-13 17:41:44,337 - INFO - Epoch [2] Batch [3250/7250] loss: 1.4127 
2025-12-13 17:42:02,464 - INFO - Epoch [2] Batch [3500/7250] loss: 1.4714 
2025-12-13 17:42:18,830 - INFO - Epoch [2] Batch [3750/7250] loss: 1.5673 
2025-12-13 17:42:35,645 - INFO - Epoch [2] Batch [4000/7250] loss: 1.4464 
2025-12-13 17:42:53,146 - INFO - Epoch [2] Batch [4250/7250] loss: 1.4886 
2025-12-13 17:43:08,614 - INFO - Epoch [2] Batch [4500/7250] loss: 1.4119 
2025-12-13 17:43:24,086 - INFO - Epoch [2] Batch [4750/7250] loss: 1.4123 
2025-12-13 17:43:39,601 - INFO - Epoch [2] Batch [5000/7250] loss: 1.4783 
2025-12-13 17:43:55,033 - INFO - Epoch [2] Batch [5250/7250] loss: 1.4146 
2025-12-13 17:44:10,556 - INFO - Epoch [2] Batch [5500/7250] loss: 1.4217 
2025-12-13 17:44:26,799 - INFO - Epoch [2] Batch [5750/7250] loss: 1.4411 
2025-12-13 17:44:44,540 - INFO - Epoch [2] Batch [6000/7250] loss: 1.6192 
2025-12-13 17:45:00,615 - INFO - Epoch [2] Batch [6250/7250] loss: 1.5461 
2025-12-13 17:45:16,217 - INFO - Epoch [2] Batch [6500/7250] loss: 1.4586 
2025-12-13 17:45:31,791 - INFO - Epoch [2] Batch [6750/7250] loss: 1.4144 
2025-12-13 17:45:47,356 - INFO - Epoch [2] Batch [7000/7250] loss: 1.4116 
2025-12-13 17:46:22,089 - INFO - Epoch [2] Batch [0/254] loss: 1.4141 
2025-12-13 17:46:22,288 - INFO - Epoch [2] Batch [10/254] loss: 1.4152 
2025-12-13 17:46:22,489 - INFO - Epoch [2] Batch [20/254] loss: 1.4832 
2025-12-13 17:46:22,693 - INFO - Epoch [2] Batch [30/254] loss: 1.4612 
2025-12-13 17:46:22,883 - INFO - Epoch [2] Batch [40/254] loss: 1.4910 
2025-12-13 17:46:23,082 - INFO - Epoch [2] Batch [50/254] loss: 1.4456 
2025-12-13 17:46:23,279 - INFO - Epoch [2] Batch [60/254] loss: 1.4606 
2025-12-13 17:46:23,476 - INFO - Epoch [2] Batch [70/254] loss: 1.4184 
2025-12-13 17:46:23,674 - INFO - Epoch [2] Batch [80/254] loss: 1.4124 
2025-12-13 17:46:23,869 - INFO - Epoch [2] Batch [90/254] loss: 1.4137 
2025-12-13 17:46:24,076 - INFO - Epoch [2] Batch [100/254] loss: 1.4227 
2025-12-13 17:46:24,274 - INFO - Epoch [2] Batch [110/254] loss: 1.4154 
2025-12-13 17:46:24,469 - INFO - Epoch [2] Batch [120/254] loss: 1.4181 
2025-12-13 17:46:24,679 - INFO - Epoch [2] Batch [130/254] loss: 1.5775 
2025-12-13 17:46:24,875 - INFO - Epoch [2] Batch [140/254] loss: 1.4183 
2025-12-13 17:46:25,062 - INFO - Epoch [2] Batch [150/254] loss: 1.4155 
2025-12-13 17:46:25,261 - INFO - Epoch [2] Batch [160/254] loss: 1.4155 
2025-12-13 17:46:25,455 - INFO - Epoch [2] Batch [170/254] loss: 1.4136 
2025-12-13 17:46:25,649 - INFO - Epoch [2] Batch [180/254] loss: 1.5030 
2025-12-13 17:46:25,851 - INFO - Epoch [2] Batch [190/254] loss: 1.4179 
2025-12-13 17:46:26,043 - INFO - Epoch [2] Batch [200/254] loss: 1.5276 
2025-12-13 17:46:26,247 - INFO - Epoch [2] Batch [210/254] loss: 1.4807 
2025-12-13 17:46:26,447 - INFO - Epoch [2] Batch [220/254] loss: 1.4643 
2025-12-13 17:46:26,640 - INFO - Epoch [2] Batch [230/254] loss: 1.4168 
2025-12-13 17:46:26,833 - INFO - Epoch [2] Batch [240/254] loss: 1.4687 
2025-12-13 17:46:27,014 - INFO - Epoch [2] Batch [250/254] loss: 1.4131 
2025-12-13 17:46:27,762 - INFO - Epoch: [2/10]Train loss: 1.4519 | Val loss: 1.4582
2025-12-13 17:46:30,003 - INFO - Epoch 2 Generated Story: fightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfightingfighting
2025-12-13 17:46:30,003 - INFO - Validation loss improved from inf to 1.4582 Saving Best model.
2025-12-13 17:46:30,916 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 2)
2025-12-13 17:46:31,740 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 2)
2025-12-13 17:46:49,569 - INFO - Epoch [3] Batch [0/7250] loss: 1.4119 
2025-12-13 17:47:05,642 - INFO - Epoch [3] Batch [250/7250] loss: 1.4099 
2025-12-13 17:47:21,363 - INFO - Epoch [3] Batch [500/7250] loss: 1.4146 
2025-12-13 17:47:37,366 - INFO - Epoch [3] Batch [750/7250] loss: 1.4113 
2025-12-13 17:47:53,683 - INFO - Epoch [3] Batch [1000/7250] loss: 1.4198 
2025-12-13 17:48:09,439 - INFO - Epoch [3] Batch [1250/7250] loss: 1.5100 
2025-12-13 17:48:25,536 - INFO - Epoch [3] Batch [1500/7250] loss: 1.4138 
2025-12-13 17:48:41,961 - INFO - Epoch [3] Batch [1750/7250] loss: 1.4144 
2025-12-13 17:48:57,799 - INFO - Epoch [3] Batch [2000/7250] loss: 1.4125 
2025-12-13 17:49:13,717 - INFO - Epoch [3] Batch [2250/7250] loss: 1.4110 
2025-12-13 17:49:29,887 - INFO - Epoch [3] Batch [2500/7250] loss: 1.4138 
2025-12-13 17:49:45,862 - INFO - Epoch [3] Batch [2750/7250] loss: 1.4568 
2025-12-13 17:50:01,618 - INFO - Epoch [3] Batch [3000/7250] loss: 1.4297 
2025-12-13 17:50:17,349 - INFO - Epoch [3] Batch [3250/7250] loss: 1.4524 
2025-12-13 17:50:33,445 - INFO - Epoch [3] Batch [3500/7250] loss: 1.4223 
2025-12-13 17:50:49,683 - INFO - Epoch [3] Batch [3750/7250] loss: 1.4115 
2025-12-13 17:51:05,835 - INFO - Epoch [3] Batch [4000/7250] loss: 1.4118 
2025-12-13 17:51:21,828 - INFO - Epoch [3] Batch [4250/7250] loss: 1.4728 
2025-12-13 17:51:37,619 - INFO - Epoch [3] Batch [4500/7250] loss: 1.4129 
2025-12-13 17:51:53,239 - INFO - Epoch [3] Batch [4750/7250] loss: 1.4099 
2025-12-13 17:52:08,825 - INFO - Epoch [3] Batch [5000/7250] loss: 1.4336 
2025-12-13 17:52:24,437 - INFO - Epoch [3] Batch [5250/7250] loss: 1.4136 
2025-12-13 17:52:40,110 - INFO - Epoch [3] Batch [5500/7250] loss: 1.4144 
2025-12-13 17:52:55,659 - INFO - Epoch [3] Batch [5750/7250] loss: 1.4405 
2025-12-13 17:53:11,324 - INFO - Epoch [3] Batch [6000/7250] loss: 1.4111 
2025-12-13 17:53:26,944 - INFO - Epoch [3] Batch [6250/7250] loss: 1.4522 
2025-12-13 17:53:42,543 - INFO - Epoch [3] Batch [6500/7250] loss: 1.4099 
2025-12-13 17:53:58,144 - INFO - Epoch [3] Batch [6750/7250] loss: 1.4251 
2025-12-13 17:54:13,741 - INFO - Epoch [3] Batch [7000/7250] loss: 1.4144 
2025-12-13 17:54:49,110 - INFO - Epoch [3] Batch [0/254] loss: 1.4134 
2025-12-13 17:54:49,379 - INFO - Epoch [3] Batch [10/254] loss: 1.4128 
2025-12-13 17:54:49,587 - INFO - Epoch [3] Batch [20/254] loss: 1.4678 
2025-12-13 17:54:49,787 - INFO - Epoch [3] Batch [30/254] loss: 1.4575 
2025-12-13 17:54:49,987 - INFO - Epoch [3] Batch [40/254] loss: 1.4897 
2025-12-13 17:54:50,190 - INFO - Epoch [3] Batch [50/254] loss: 1.4315 
2025-12-13 17:54:50,427 - INFO - Epoch [3] Batch [60/254] loss: 1.4475 
2025-12-13 17:54:50,640 - INFO - Epoch [3] Batch [70/254] loss: 1.4154 
2025-12-13 17:54:50,846 - INFO - Epoch [3] Batch [80/254] loss: 1.4144 
2025-12-13 17:54:51,080 - INFO - Epoch [3] Batch [90/254] loss: 1.4152 
2025-12-13 17:54:51,309 - INFO - Epoch [3] Batch [100/254] loss: 1.4169 
2025-12-13 17:54:51,520 - INFO - Epoch [3] Batch [110/254] loss: 1.4133 
2025-12-13 17:54:51,748 - INFO - Epoch [3] Batch [120/254] loss: 1.4151 
2025-12-13 17:54:51,985 - INFO - Epoch [3] Batch [130/254] loss: 1.5562 
2025-12-13 17:54:52,209 - INFO - Epoch [3] Batch [140/254] loss: 1.4179 
2025-12-13 17:54:52,418 - INFO - Epoch [3] Batch [150/254] loss: 1.4181 
2025-12-13 17:54:52,634 - INFO - Epoch [3] Batch [160/254] loss: 1.4132 
2025-12-13 17:54:52,836 - INFO - Epoch [3] Batch [170/254] loss: 1.4136 
2025-12-13 17:54:53,036 - INFO - Epoch [3] Batch [180/254] loss: 1.4885 
2025-12-13 17:54:53,233 - INFO - Epoch [3] Batch [190/254] loss: 1.4144 
2025-12-13 17:54:53,468 - INFO - Epoch [3] Batch [200/254] loss: 1.5162 
2025-12-13 17:54:53,693 - INFO - Epoch [3] Batch [210/254] loss: 1.4819 
2025-12-13 17:54:53,891 - INFO - Epoch [3] Batch [220/254] loss: 1.4861 
2025-12-13 17:54:54,099 - INFO - Epoch [3] Batch [230/254] loss: 1.4182 
2025-12-13 17:54:54,322 - INFO - Epoch [3] Batch [240/254] loss: 1.4534 
2025-12-13 17:54:54,525 - INFO - Epoch [3] Batch [250/254] loss: 1.4130 
2025-12-13 17:54:55,299 - INFO - Epoch: [3/10]Train loss: 1.4387 | Val loss: 1.4587
2025-12-13 17:54:56,999 - INFO - Epoch 3 Generated Story: grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded grounded
2025-12-13 17:54:57,000 - INFO - Validation loss did not improve. Current best loss: 1.4582
2025-12-13 17:54:57,925 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 3)
2025-12-13 17:55:16,424 - INFO - Epoch [4] Batch [0/7250] loss: 1.5081 
2025-12-13 17:55:32,022 - INFO - Epoch [4] Batch [250/7250] loss: 1.4139 
2025-12-13 17:55:47,415 - INFO - Epoch [4] Batch [500/7250] loss: 1.4294 
2025-12-13 17:56:02,879 - INFO - Epoch [4] Batch [750/7250] loss: 1.4145 
2025-12-13 17:56:18,345 - INFO - Epoch [4] Batch [1000/7250] loss: 1.4095 
2025-12-13 17:56:33,860 - INFO - Epoch [4] Batch [1250/7250] loss: 1.4132 
2025-12-13 17:56:49,303 - INFO - Epoch [4] Batch [1500/7250] loss: 1.4131 
2025-12-13 17:57:04,835 - INFO - Epoch [4] Batch [1750/7250] loss: 1.4115 
2025-12-13 17:57:20,352 - INFO - Epoch [4] Batch [2000/7250] loss: 1.4130 
2025-12-13 17:57:35,943 - INFO - Epoch [4] Batch [2250/7250] loss: 1.4150 
2025-12-13 17:57:51,471 - INFO - Epoch [4] Batch [2500/7250] loss: 1.4412 
2025-12-13 17:58:07,023 - INFO - Epoch [4] Batch [2750/7250] loss: 1.4397 
2025-12-13 17:58:22,581 - INFO - Epoch [4] Batch [3000/7250] loss: 1.4361 
2025-12-13 17:58:38,174 - INFO - Epoch [4] Batch [3250/7250] loss: 1.4133 
2025-12-13 17:58:53,880 - INFO - Epoch [4] Batch [3500/7250] loss: 1.4105 
2025-12-13 17:59:09,448 - INFO - Epoch [4] Batch [3750/7250] loss: 1.5341 
2025-12-13 17:59:25,322 - INFO - Epoch [4] Batch [4000/7250] loss: 1.4106 
2025-12-13 17:59:41,470 - INFO - Epoch [4] Batch [4250/7250] loss: 1.4182 
2025-12-13 17:59:57,656 - INFO - Epoch [4] Batch [4500/7250] loss: 1.4664 
2025-12-13 18:00:13,620 - INFO - Epoch [4] Batch [4750/7250] loss: 1.4132 
2025-12-13 18:00:29,146 - INFO - Epoch [4] Batch [5000/7250] loss: 1.4096 
2025-12-13 18:00:44,611 - INFO - Epoch [4] Batch [5250/7250] loss: 1.4572 
2025-12-13 18:01:00,150 - INFO - Epoch [4] Batch [5500/7250] loss: 1.4378 
2025-12-13 18:01:15,714 - INFO - Epoch [4] Batch [5750/7250] loss: 1.4577 
2025-12-13 18:01:31,545 - INFO - Epoch [4] Batch [6000/7250] loss: 1.5354 
2025-12-13 18:01:47,071 - INFO - Epoch [4] Batch [6250/7250] loss: 1.4113 
2025-12-13 18:02:02,593 - INFO - Epoch [4] Batch [6500/7250] loss: 1.4112 
2025-12-13 18:02:18,153 - INFO - Epoch [4] Batch [6750/7250] loss: 1.4115 
2025-12-13 18:02:33,799 - INFO - Epoch [4] Batch [7000/7250] loss: 1.4594 
2025-12-13 18:03:09,033 - INFO - Epoch [4] Batch [0/254] loss: 1.4126 
2025-12-13 18:03:09,423 - INFO - Epoch [4] Batch [10/254] loss: 1.4115 
2025-12-13 18:03:09,615 - INFO - Epoch [4] Batch [20/254] loss: 1.4484 
2025-12-13 18:03:09,814 - INFO - Epoch [4] Batch [30/254] loss: 1.4459 
2025-12-13 18:03:10,012 - INFO - Epoch [4] Batch [40/254] loss: 1.4906 
2025-12-13 18:03:10,210 - INFO - Epoch [4] Batch [50/254] loss: 1.4194 
2025-12-13 18:03:10,408 - INFO - Epoch [4] Batch [60/254] loss: 1.4325 
2025-12-13 18:03:10,611 - INFO - Epoch [4] Batch [70/254] loss: 1.4146 
2025-12-13 18:03:10,805 - INFO - Epoch [4] Batch [80/254] loss: 1.4137 
2025-12-13 18:03:11,003 - INFO - Epoch [4] Batch [90/254] loss: 1.4136 
2025-12-13 18:03:11,199 - INFO - Epoch [4] Batch [100/254] loss: 1.4156 
2025-12-13 18:03:11,401 - INFO - Epoch [4] Batch [110/254] loss: 1.4136 
2025-12-13 18:03:11,609 - INFO - Epoch [4] Batch [120/254] loss: 1.4150 
2025-12-13 18:03:11,819 - INFO - Epoch [4] Batch [130/254] loss: 1.5475 
2025-12-13 18:03:12,021 - INFO - Epoch [4] Batch [140/254] loss: 1.4163 
2025-12-13 18:03:12,224 - INFO - Epoch [4] Batch [150/254] loss: 1.4168 
2025-12-13 18:03:12,429 - INFO - Epoch [4] Batch [160/254] loss: 1.4136 
2025-12-13 18:03:12,632 - INFO - Epoch [4] Batch [170/254] loss: 1.4129 
2025-12-13 18:03:12,832 - INFO - Epoch [4] Batch [180/254] loss: 1.4791 
2025-12-13 18:03:13,034 - INFO - Epoch [4] Batch [190/254] loss: 1.4140 
2025-12-13 18:03:13,225 - INFO - Epoch [4] Batch [200/254] loss: 1.4998 
2025-12-13 18:03:13,426 - INFO - Epoch [4] Batch [210/254] loss: 1.4782 
2025-12-13 18:03:13,624 - INFO - Epoch [4] Batch [220/254] loss: 1.4871 
2025-12-13 18:03:13,829 - INFO - Epoch [4] Batch [230/254] loss: 1.4142 
2025-12-13 18:03:14,037 - INFO - Epoch [4] Batch [240/254] loss: 1.4448 
2025-12-13 18:03:14,251 - INFO - Epoch [4] Batch [250/254] loss: 1.4129 
2025-12-13 18:03:14,997 - INFO - Epoch: [4/10]Train loss: 1.4310 | Val loss: 1.4568
2025-12-13 18:03:16,644 - INFO - Epoch 4 Generated Story: boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling boiling
2025-12-13 18:03:16,644 - INFO - Validation loss improved from 1.4582 to 1.4568 Saving Best model.
2025-12-13 18:03:17,547 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 4)
2025-12-13 18:03:18,403 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 4)
2025-12-13 18:03:36,446 - INFO - Epoch [5] Batch [0/7250] loss: 1.4362 
2025-12-13 18:03:52,021 - INFO - Epoch [5] Batch [250/7250] loss: 1.4100 
2025-12-13 18:04:07,460 - INFO - Epoch [5] Batch [500/7250] loss: 1.4126 
2025-12-13 18:04:22,943 - INFO - Epoch [5] Batch [750/7250] loss: 1.4116 
2025-12-13 18:04:38,422 - INFO - Epoch [5] Batch [1000/7250] loss: 1.4181 
2025-12-13 18:04:54,046 - INFO - Epoch [5] Batch [1250/7250] loss: 1.4140 
2025-12-13 18:05:09,711 - INFO - Epoch [5] Batch [1500/7250] loss: 1.4133 
2025-12-13 18:05:25,645 - INFO - Epoch [5] Batch [1750/7250] loss: 1.5026 
2025-12-13 18:05:42,158 - INFO - Epoch [5] Batch [2000/7250] loss: 1.4185 
2025-12-19 19:34:27,214 - INFO - Generated Story: air on an outdoor garden patio until the feeling was all that remained. In the background, the field feels sad in early morning
2025-12-19 19:34:27,214 - INFO - Validation loss improved from 1.3452 to 1.3355. Saving Best model.
2025-12-19 19:34:28,288 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 6)
2025-12-19 19:34:29,312 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 6)
2025-12-19 19:34:56,543 - INFO - Epoch [7] Batch [0/3625] loss: 1.4199 
2025-12-19 19:37:25,953 - INFO - Epoch [7] Batch [1200/3625] loss: 1.0973 
2025-12-19 19:39:54,144 - INFO - Epoch [7] Batch [2400/3625] loss: 1.2638 
2025-12-19 19:42:23,093 - INFO - Epoch [7] Batch [3600/3625] loss: 1.5874 
2025-12-19 19:42:55,312 - INFO - Epoch [7] Batch [0/127] loss: 1.1285 
2025-12-19 19:42:56,191 - INFO - Epoch [7] Batch [20/127] loss: 1.4316 
2025-12-19 19:42:57,060 - INFO - Epoch [7] Batch [40/127] loss: 1.3808 
2025-12-19 19:42:57,916 - INFO - Epoch [7] Batch [60/127] loss: 1.3792 
2025-12-19 19:42:58,778 - INFO - Epoch [7] Batch [80/127] loss: 1.1230 
2025-12-19 19:42:59,642 - INFO - Epoch [7] Batch [100/127] loss: 1.4287 
2025-12-19 19:43:00,502 - INFO - Epoch [7] Batch [120/127] loss: 1.5377 
2025-12-19 19:43:01,884 - INFO - Epoch: [7/15]Train loss: 1.2652 | Val loss: 1.3344
2025-12-19 19:43:01,884 - INFO - --- Generating Sample Story for Epoch 7 ---
2025-12-19 19:43:03,532 - INFO - Generated Story: until the feeling was all that remained. In the background, the street feels lonely just before the rain
2025-12-19 19:43:03,532 - INFO - Validation loss improved from 1.3355 to 1.3344. Saving Best model.
2025-12-19 19:43:04,565 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 7)
2025-12-19 19:43:05,608 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 7)
2025-12-19 19:43:32,595 - INFO - Epoch [8] Batch [0/3625] loss: 1.1436 
2025-12-19 19:46:00,079 - INFO - Epoch [8] Batch [1200/3625] loss: 1.3552 
2025-12-19 19:48:30,021 - INFO - Epoch [8] Batch [2400/3625] loss: 1.1363 
2025-12-19 19:50:58,950 - INFO - Epoch [8] Batch [3600/3625] loss: 1.2386 
2025-12-19 19:51:32,977 - INFO - Epoch [8] Batch [0/127] loss: 1.1298 
2025-12-19 19:51:33,873 - INFO - Epoch [8] Batch [20/127] loss: 1.4668 
2025-12-19 19:51:34,755 - INFO - Epoch [8] Batch [40/127] loss: 1.3849 
2025-12-19 19:51:35,628 - INFO - Epoch [8] Batch [60/127] loss: 1.4328 
2025-12-19 19:51:36,505 - INFO - Epoch [8] Batch [80/127] loss: 1.1510 
2025-12-19 19:51:37,379 - INFO - Epoch [8] Batch [100/127] loss: 1.4392 
2025-12-19 19:51:38,257 - INFO - Epoch [8] Batch [120/127] loss: 1.5978 
2025-12-19 19:51:39,661 - INFO - Epoch: [8/15]Train loss: 1.2204 | Val loss: 1.3454
2025-12-19 19:51:39,661 - INFO - --- Generating Sample Story for Epoch 8 ---
2025-12-19 19:51:41,858 - INFO - Generated Story: a stillness that felt both fragile and absolute. In the background, the stadium feels sad just before the rain
2025-12-19 19:51:41,858 - INFO - Validation loss did not improve. Current best loss: 1.3344 (Patience: 1/5)
2025-12-19 19:51:42,918 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 8)
2025-12-19 19:52:10,050 - INFO - Epoch [9] Batch [0/3625] loss: 1.2891 
2025-12-19 19:54:37,334 - INFO - Epoch [9] Batch [1200/3625] loss: 1.1785 
2025-12-19 19:57:06,443 - INFO - Epoch [9] Batch [2400/3625] loss: 1.3364 
2025-12-19 19:59:33,263 - INFO - Epoch [9] Batch [3600/3625] loss: 1.0785 
2025-12-19 20:00:05,621 - INFO - Epoch [9] Batch [0/127] loss: 1.1315 
2025-12-19 20:00:06,518 - INFO - Epoch [9] Batch [20/127] loss: 1.5054 
2025-12-19 20:00:07,388 - INFO - Epoch [9] Batch [40/127] loss: 1.3958 
2025-12-19 20:00:08,263 - INFO - Epoch [9] Batch [60/127] loss: 1.4639 
2025-12-19 20:00:09,136 - INFO - Epoch [9] Batch [80/127] loss: 1.1297 
2025-12-19 20:00:10,012 - INFO - Epoch [9] Batch [100/127] loss: 1.4463 
2025-12-19 20:00:10,886 - INFO - Epoch [9] Batch [120/127] loss: 1.6102 
2025-12-19 20:00:12,272 - INFO - Epoch: [9/15]Train loss: 1.1805 | Val loss: 1.3591
2025-12-19 20:00:12,272 - INFO - --- Generating Sample Story for Epoch 9 ---
2025-12-19 20:00:13,916 - INFO - Generated Story: was all that remained. In the background, the field feels playful late at night
2025-12-19 20:00:13,916 - INFO - Validation loss did not improve. Current best loss: 1.3344 (Patience: 2/5)
2025-12-19 20:00:15,000 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 9)
2025-12-19 20:00:41,706 - INFO - Epoch [10] Batch [0/3625] loss: 1.1569 
2025-12-19 20:03:08,720 - INFO - Epoch [10] Batch [1200/3625] loss: 1.0450 
2025-12-19 20:05:35,972 - INFO - Epoch [10] Batch [2400/3625] loss: 1.0193 
2025-12-19 20:08:05,484 - INFO - Epoch [10] Batch [3600/3625] loss: 1.2234 
2025-12-19 20:08:39,474 - INFO - Epoch [10] Batch [0/127] loss: 1.1793 
2025-12-19 20:08:40,516 - INFO - Epoch [10] Batch [20/127] loss: 1.4910 
2025-12-19 20:08:41,432 - INFO - Epoch [10] Batch [40/127] loss: 1.4165 
2025-12-19 20:08:42,356 - INFO - Epoch [10] Batch [60/127] loss: 1.4329 
2025-12-19 20:08:43,287 - INFO - Epoch [10] Batch [80/127] loss: 1.1256 
2025-12-19 20:08:44,217 - INFO - Epoch [10] Batch [100/127] loss: 1.4593 
2025-12-19 20:08:45,135 - INFO - Epoch [10] Batch [120/127] loss: 1.6359 
2025-12-19 20:08:46,656 - INFO - Epoch: [10/15]Train loss: 1.1414 | Val loss: 1.3704
2025-12-19 20:08:46,656 - INFO - --- Generating Sample Story for Epoch 10 ---
2025-12-19 20:08:48,414 - INFO - Generated Story: shown in a stillness that felt both fragile, absolute. In the background, the ocean feels tense just before the rain
2025-12-19 20:08:48,414 - INFO - Validation loss did not improve. Current best loss: 1.3344 (Patience: 3/5)
2025-12-19 20:08:48,414 - INFO - Manually reducing LR from 5.00e-05 to 5.00e-06
2025-12-19 20:08:49,529 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 10)
2025-12-19 20:09:16,749 - INFO - Epoch [11] Batch [0/3625] loss: 1.0076 
2025-12-19 20:11:45,658 - INFO - Epoch [11] Batch [1200/3625] loss: 1.1404 
2025-12-19 20:14:12,505 - INFO - Epoch [11] Batch [2400/3625] loss: 1.1095 
2025-12-19 20:16:41,888 - INFO - Epoch [11] Batch [3600/3625] loss: 1.0559 
2025-12-19 20:17:15,731 - INFO - Epoch [11] Batch [0/127] loss: 1.1817 
2025-12-19 20:17:16,659 - INFO - Epoch [11] Batch [20/127] loss: 1.5228 
2025-12-19 20:17:17,568 - INFO - Epoch [11] Batch [40/127] loss: 1.4164 
2025-12-19 20:17:18,482 - INFO - Epoch [11] Batch [60/127] loss: 1.4923 
2025-12-19 20:17:19,394 - INFO - Epoch [11] Batch [80/127] loss: 1.1180 
2025-12-19 20:17:20,302 - INFO - Epoch [11] Batch [100/127] loss: 1.4765 
2025-12-19 20:17:21,230 - INFO - Epoch [11] Batch [120/127] loss: 1.6602 
2025-12-19 20:17:22,753 - INFO - Epoch: [11/15]Train loss: 1.0717 | Val loss: 1.3897
2025-12-19 20:17:22,753 - INFO - --- Generating Sample Story for Epoch 11 ---
2025-12-19 20:17:25,886 - INFO - Generated Story: green fence in front of them with trees while everything else fades into the background. In the distant, the market feels sad just before the rain
2025-12-19 20:17:25,886 - INFO - Validation loss did not improve. Current best loss: 1.3344 (Patience: 4/5)
2025-12-19 20:17:26,958 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 11)
2025-12-19 20:17:55,427 - INFO - Epoch [12] Batch [0/3625] loss: 1.0505 
2025-12-19 20:20:25,267 - INFO - Epoch [12] Batch [1200/3625] loss: 1.0788 
2025-12-19 20:22:54,422 - INFO - Epoch [12] Batch [2400/3625] loss: 0.9975 
2025-12-19 20:25:21,576 - INFO - Epoch [12] Batch [3600/3625] loss: 0.9082 
2025-12-19 20:25:53,393 - INFO - Epoch [12] Batch [0/127] loss: 1.1864 
2025-12-19 20:25:54,398 - INFO - Epoch [12] Batch [20/127] loss: 1.5247 
2025-12-19 20:25:55,373 - INFO - Epoch [12] Batch [40/127] loss: 1.4209 
2025-12-19 20:25:56,365 - INFO - Epoch [12] Batch [60/127] loss: 1.5039 
2025-12-19 20:25:57,271 - INFO - Epoch [12] Batch [80/127] loss: 1.1227 
2025-12-19 20:25:58,165 - INFO - Epoch [12] Batch [100/127] loss: 1.4819 
2025-12-19 20:25:59,049 - INFO - Epoch [12] Batch [120/127] loss: 1.6625 
2025-12-19 20:26:00,422 - INFO - Epoch: [12/15]Train loss: 1.0600 | Val loss: 1.3931
2025-12-19 20:26:00,427 - INFO - --- Generating Sample Story for Epoch 12 ---
2025-12-19 20:26:02,240 - INFO - Generated Story: world moves quietly around. In the background, the city feels sad in the early morning
2025-12-19 20:26:02,240 - INFO - Validation loss did not improve. Current best loss: 1.3344 (Patience: 5/5)
2025-12-19 20:26:02,240 - INFO - Early stopping triggered after 5 epochs without improvement
2025-12-27 18:24:28,451 - INFO - Logging initialize successfully
2025-12-27 18:24:28,577 - INFO - Loaded 29000 rows for split='train'.
2025-12-27 18:24:28,693 - INFO - Loaded 1014 rows for split='val'.
2025-12-27 18:24:30,089 - INFO - Built 29000 samples from annotaions
2025-12-27 18:24:30,089 - INFO - Total train samples: 29000
2025-12-27 18:24:30,129 - INFO - Built 1014 samples from annotaions
2025-12-27 18:24:30,129 - INFO - Total val samples: 1014
2025-12-27 18:24:30,151 - INFO - Built 29000 samples for story 
2025-12-27 18:24:30,151 - INFO - Built 1014 samples for story 
2025-12-27 18:24:30,287 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-27 18:24:30,287 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-27 18:24:34,884 - INFO - Model initialized. Trainable parameters: 68531712
2025-12-27 18:28:46,288 - ERROR - Runtime Error (e.g., OOM) encountered at batch 55: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-27 18:28:46,293 - ERROR - Runtime Error (e.g., OOM) encountered at batch 56: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
2025-12-27 22:00:58,417 - INFO - Logging initialize successfully
2025-12-27 22:00:58,545 - INFO - Loaded 29000 rows for split='train'.
2025-12-27 22:00:58,665 - INFO - Loaded 1014 rows for split='val'.
2025-12-27 22:01:00,031 - INFO - Built 29000 samples from annotaions
2025-12-27 22:01:00,031 - INFO - Total train samples: 29000
2025-12-27 22:01:00,078 - INFO - Built 1014 samples from annotaions
2025-12-27 22:01:00,078 - INFO - Total val samples: 1014
2025-12-27 22:01:00,100 - INFO - Built 29000 samples for story 
2025-12-27 22:01:00,101 - INFO - Built 1014 samples for story 
2025-12-27 22:01:00,227 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-27 22:01:00,227 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-27 22:01:05,165 - INFO - Model initialized. Trainable parameters: 68534016
2025-12-27 22:01:05,165 - INFO - Resume enabled but no valid checkpoint found. Starting from scratch.
2025-12-27 22:01:21,210 - INFO - Epoch [1] Batch [0/3625] loss: 80.9938 
2025-12-27 22:04:39,587 - INFO - Epoch [1] Batch [1200/3625] loss: 1.3571 
2025-12-27 22:07:59,418 - INFO - Epoch [1] Batch [2400/3625] loss: 1.5956 
2025-12-27 22:11:19,951 - INFO - Epoch [1] Batch [3600/3625] loss: 1.2469 
2025-12-27 22:11:40,612 - INFO - Epoch [1] Batch [0/127] loss: 1.1997 
2025-12-27 22:11:41,905 - INFO - Epoch [1] Batch [20/127] loss: 1.2406 
2025-12-27 22:11:43,184 - INFO - Epoch [1] Batch [40/127] loss: 1.2880 
2025-12-27 22:11:44,451 - INFO - Epoch [1] Batch [60/127] loss: 1.3158 
2025-12-27 22:11:45,731 - INFO - Epoch [1] Batch [80/127] loss: 1.3177 
2025-12-27 22:11:47,020 - INFO - Epoch [1] Batch [100/127] loss: 1.4083 
2025-12-27 22:11:48,292 - INFO - Epoch [1] Batch [120/127] loss: 1.2390 
2025-12-27 22:11:49,394 - INFO - Epoch: [1/20]Train loss: 1.6206 | Val loss: 1.2820
2025-12-27 22:11:49,394 - INFO - --- Generating Sample Story for Epoch 1 ---
2025-12-27 22:11:50,942 - INFO - Generated Story: Story generation temporarily disabled due to compatibility issues
2025-12-27 22:11:50,942 - INFO - Validation loss improved from 10.0000 to 1.2820. Saving Best model.
2025-12-27 22:11:52,032 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 1)
2025-12-27 22:11:53,047 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 1)
2025-12-27 22:12:08,729 - INFO - Epoch [2] Batch [0/3625] loss: 1.2877 
2025-12-27 22:15:27,332 - INFO - Epoch [2] Batch [1200/3625] loss: 1.2315 
2025-12-27 22:18:47,466 - INFO - Epoch [2] Batch [2400/3625] loss: 1.3379 
2025-12-27 22:22:08,338 - INFO - Epoch [2] Batch [3600/3625] loss: 1.1439 
2025-12-27 22:22:28,811 - INFO - Epoch [2] Batch [0/127] loss: 1.1763 
2025-12-27 22:22:30,108 - INFO - Epoch [2] Batch [20/127] loss: 1.2088 
2025-12-27 22:22:31,384 - INFO - Epoch [2] Batch [40/127] loss: 1.2217 
2025-12-27 22:22:32,657 - INFO - Epoch [2] Batch [60/127] loss: 1.2463 
2025-12-27 22:22:33,932 - INFO - Epoch [2] Batch [80/127] loss: 1.2557 
2025-12-27 22:22:35,204 - INFO - Epoch [2] Batch [100/127] loss: 1.3802 
2025-12-27 22:22:36,481 - INFO - Epoch [2] Batch [120/127] loss: 1.2171 
2025-12-27 22:22:37,620 - INFO - Epoch: [2/20]Train loss: 1.2517 | Val loss: 1.2477
2025-12-27 22:22:37,620 - INFO - --- Generating Sample Story for Epoch 2 ---
2025-12-27 22:22:38,221 - INFO - Generated Story: Story generation temporarily disabled due to compatibility issues
2025-12-27 22:22:38,221 - INFO - Validation loss improved from 1.2820 to 1.2477. Saving Best model.
2025-12-27 22:22:39,308 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 2)
2025-12-27 22:22:40,446 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 2)
2025-12-27 22:22:55,758 - INFO - Epoch [3] Batch [0/3625] loss: 1.2050 
2025-12-28 14:57:27,362 - INFO - Logging initialize successfully
2025-12-28 14:57:27,498 - INFO - Loaded 29000 rows for split='train'.
2025-12-28 14:57:27,621 - INFO - Loaded 1014 rows for split='val'.
2025-12-28 14:57:29,003 - INFO - Built 29000 samples from annotaions
2025-12-28 14:57:29,005 - INFO - Total train samples: 29000
2025-12-28 14:57:29,039 - INFO - Built 1014 samples from annotaions
2025-12-28 14:57:29,039 - INFO - Total val samples: 1014
2025-12-28 14:57:29,061 - INFO - Built 29000 samples for story 
2025-12-28 14:57:29,063 - INFO - Built 1014 samples for story 
2025-12-28 14:57:29,197 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-28 14:57:29,202 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-28 14:57:34,283 - INFO - Model initialized. Trainable parameters: 68534016
2025-12-28 14:57:35,708 - INFO - Checkpoint loaded from checkpoints/latest.pth. Resuming at epoch 2. (Scheduler restored: True, Scaler restored: True)
2025-12-28 14:57:35,708 - INFO - Checkpoint loaded from checkpoints/latest.pth (LATEST (Better Performance)). Resuming training from epoch 3, best loss tracked: 1.2477
2025-12-28 14:57:51,797 - INFO - Epoch [3] Batch [0/3625] loss: 1.0973 
2025-12-28 15:01:12,886 - INFO - Epoch [3] Batch [1200/3625] loss: 1.2339 
2025-12-28 15:04:38,397 - INFO - Epoch [3] Batch [2400/3625] loss: 1.0389 
2025-12-28 15:08:02,694 - INFO - Epoch [3] Batch [3600/3625] loss: 1.3640 
2025-12-28 15:08:24,150 - INFO - Epoch [3] Batch [0/127] loss: 1.1784 
2025-12-28 15:08:27,939 - INFO - Epoch [3] Batch [60/127] loss: 1.2320 
2025-12-28 15:08:31,716 - INFO - Epoch [3] Batch [120/127] loss: 1.1899 
2025-12-28 15:08:32,823 - INFO - Epoch: [3/20]Train loss: 1.1603 | Val loss: 1.2415
2025-12-28 15:08:32,827 - INFO - --- Generating Sample Story for Epoch 3 ---
2025-12-28 15:08:34,328 - INFO - Generated Story: Story generation temporarily disabled due to compatibility issues
2025-12-28 15:08:34,328 - INFO - Validation loss improved from 1.2477 to 1.2415. Saving Best model.
2025-12-28 15:08:35,494 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 3)
2025-12-28 15:08:36,577 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 3)
2025-12-28 15:08:52,671 - INFO - Epoch [4] Batch [0/3625] loss: 1.0136 
2025-12-28 15:12:16,687 - INFO - Epoch [4] Batch [1200/3625] loss: 1.1006 
2025-12-28 15:15:40,215 - INFO - Epoch [4] Batch [2400/3625] loss: 1.1207 
2025-12-28 15:19:02,586 - INFO - Epoch [4] Batch [3600/3625] loss: 0.9733 
2025-12-28 15:19:23,559 - INFO - Epoch [4] Batch [0/127] loss: 1.1662 
2025-12-28 15:19:27,292 - INFO - Epoch [4] Batch [60/127] loss: 1.2357 
2025-12-28 15:19:31,030 - INFO - Epoch [4] Batch [120/127] loss: 1.2094 
2025-12-28 15:19:32,087 - INFO - Epoch: [4/20]Train loss: 1.0854 | Val loss: 1.2427
2025-12-28 15:19:32,087 - INFO - --- Generating Sample Story for Epoch 4 ---
2025-12-28 15:19:32,724 - INFO - Generated Story: Story generation temporarily disabled due to compatibility issues
2025-12-28 15:19:32,724 - INFO - Validation loss did not improve. Current best loss: 1.2415 (Patience: 1/5)
2025-12-28 15:19:33,818 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 4)
2025-12-28 15:19:49,289 - INFO - Epoch [5] Batch [0/3625] loss: 0.9598 
2025-12-28 15:23:11,300 - INFO - Epoch [5] Batch [1200/3625] loss: 1.1109 
2025-12-28 15:26:34,374 - INFO - Epoch [5] Batch [2400/3625] loss: 1.1721 
2025-12-28 15:29:58,746 - INFO - Epoch [5] Batch [3600/3625] loss: 1.1147 
2025-12-28 15:30:18,795 - INFO - Epoch [5] Batch [0/127] loss: 1.1933 
2025-12-28 15:30:22,519 - INFO - Epoch [5] Batch [60/127] loss: 1.2495 
2025-12-28 15:30:26,254 - INFO - Epoch [5] Batch [120/127] loss: 1.2355 
2025-12-28 15:30:27,297 - INFO - Epoch: [5/20]Train loss: 1.0171 | Val loss: 1.2693
2025-12-28 15:30:27,298 - INFO - --- Generating Sample Story for Epoch 5 ---
2025-12-28 15:30:27,838 - INFO - Generated Story: Story generation temporarily disabled due to compatibility issues
2025-12-28 15:30:27,839 - INFO - Validation loss did not improve. Current best loss: 1.2415 (Patience: 2/5)
2025-12-28 15:30:28,942 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 5)
2025-12-28 15:34:42,928 - INFO - Logging initialize successfully
2025-12-28 15:34:43,058 - INFO - Loaded 29000 rows for split='train'.
2025-12-28 15:34:43,195 - INFO - Loaded 1014 rows for split='val'.
2025-12-28 15:34:44,608 - INFO - Built 29000 samples from annotaions
2025-12-28 15:34:44,609 - INFO - Total train samples: 29000
2025-12-28 15:34:44,645 - INFO - Built 1014 samples from annotaions
2025-12-28 15:34:44,645 - INFO - Total val samples: 1014
2025-12-28 15:34:44,667 - INFO - Built 29000 samples for story 
2025-12-28 15:34:44,667 - INFO - Built 1014 samples for story 
2025-12-28 15:34:44,806 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-28 15:34:44,811 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-28 15:34:50,071 - INFO - Model initialized. Trainable parameters: 68534016
2025-12-28 15:34:51,636 - INFO - Checkpoint loaded from checkpoints/latest.pth. Resuming at epoch 5. (Scheduler restored: True, Scaler restored: True)
2025-12-28 15:34:51,636 - INFO - Checkpoint loaded from checkpoints/latest.pth (LATEST (Better Performance)). Resuming training from epoch 6, best loss tracked: 1.2415
2025-12-28 15:35:08,393 - INFO - Epoch [6] Batch [0/3625] loss: 1.0392 
2025-12-28 15:38:41,241 - INFO - Epoch [6] Batch [1200/3625] loss: 0.8567 
2025-12-28 15:42:04,990 - INFO - Epoch [6] Batch [2400/3625] loss: 0.8136 
2025-12-28 15:45:27,060 - INFO - Epoch [6] Batch [3600/3625] loss: 0.9902 
2025-12-28 15:45:47,520 - INFO - Epoch [6] Batch [0/127] loss: 1.2361 
2025-12-28 15:45:51,225 - INFO - Epoch [6] Batch [60/127] loss: 1.3126 
2025-12-28 15:45:54,944 - INFO - Epoch [6] Batch [120/127] loss: 1.2844 
2025-12-28 15:45:56,008 - INFO - Epoch: [6/20]Train loss: 0.9534 | Val loss: 1.3020
2025-12-28 15:45:56,008 - INFO - --- Generating Sample Story for Epoch 6 ---
2025-12-28 15:45:56,762 - INFO - Generated Story: A story about  a  man  in  a  black  shirt  and  jeans  standing  in  front  of  a  store .
2025-12-28 15:45:56,762 - INFO - Validation loss did not improve. Current best loss: 1.2415 (Patience: 1/5)
2025-12-28 15:45:57,837 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 6)
2025-12-28 15:46:13,038 - INFO - Epoch [7] Batch [0/3625] loss: 0.8231 
2025-12-28 15:49:35,707 - INFO - Epoch [7] Batch [1200/3625] loss: 0.9512 
2025-12-28 15:52:57,702 - INFO - Epoch [7] Batch [2400/3625] loss: 0.9450 
2025-12-28 15:56:19,725 - INFO - Epoch [7] Batch [3600/3625] loss: 0.9701 
2025-12-28 15:56:39,330 - INFO - Epoch [7] Batch [0/127] loss: 1.2074 
2025-12-28 15:56:43,042 - INFO - Epoch [7] Batch [60/127] loss: 1.3205 
2025-12-28 15:56:46,791 - INFO - Epoch [7] Batch [120/127] loss: 1.3489 
2025-12-28 15:56:47,848 - INFO - Epoch: [7/20]Train loss: 0.8908 | Val loss: 1.3237
2025-12-28 15:56:47,848 - INFO - --- Generating Sample Story for Epoch 7 ---
2025-12-28 15:56:48,540 - INFO - Generated Story: A story about  a  man  in  a  black  shirt  and  blue  jeans  standing  in  front  of  a  yellow
2025-12-28 15:56:48,540 - INFO - Validation loss did not improve. Current best loss: 1.2415 (Patience: 2/5)
2025-12-28 15:56:49,617 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 7)
2025-12-28 15:57:05,053 - INFO - Epoch [8] Batch [0/3625] loss: 0.8166 
2025-12-28 16:00:28,440 - INFO - Epoch [8] Batch [1200/3625] loss: 0.7064 
2025-12-28 16:03:51,129 - INFO - Epoch [8] Batch [2400/3625] loss: 0.7755 
2025-12-28 16:07:14,314 - INFO - Epoch [8] Batch [3600/3625] loss: 0.7300 
2025-12-28 16:07:35,339 - INFO - Epoch [8] Batch [0/127] loss: 1.2714 
2025-12-28 16:07:39,059 - INFO - Epoch [8] Batch [60/127] loss: 1.3769 
2025-12-28 16:07:42,805 - INFO - Epoch [8] Batch [120/127] loss: 1.3917 
2025-12-28 16:07:43,839 - INFO - Epoch: [8/20]Train loss: 0.7947 | Val loss: 1.3812
2025-12-28 16:07:43,839 - INFO - --- Generating Sample Story for Epoch 8 ---
2025-12-28 16:07:44,388 - INFO - Generated Story: A story about  a  woman  in  a  black  dress  and  holding  a  white  bag . [STORY] A story
2025-12-28 16:07:44,388 - INFO - Validation loss did not improve. Current best loss: 1.2415 (Patience: 3/5)
2025-12-28 16:07:44,388 - INFO - Manually reducing LR from 5.00e-05 to 5.00e-06
2025-12-28 16:07:45,495 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 8)
2025-12-28 16:08:00,670 - INFO - Epoch [9] Batch [0/3625] loss: 0.7277 
2025-12-28 16:11:22,337 - INFO - Epoch [9] Batch [1200/3625] loss: 0.7000 
2025-12-28 16:14:44,390 - INFO - Epoch [9] Batch [2400/3625] loss: 0.8050 
2025-12-28 16:18:06,935 - INFO - Epoch [9] Batch [3600/3625] loss: 0.8029 
2025-12-28 16:18:26,552 - INFO - Epoch [9] Batch [0/127] loss: 1.3001 
2025-12-28 16:18:30,302 - INFO - Epoch [9] Batch [60/127] loss: 1.3992 
2025-12-28 16:18:34,053 - INFO - Epoch [9] Batch [120/127] loss: 1.4460 
2025-12-28 16:18:35,097 - INFO - Epoch: [9/20]Train loss: 0.7265 | Val loss: 1.4208
2025-12-28 16:18:35,097 - INFO - --- Generating Sample Story for Epoch 9 ---
2025-12-28 16:18:35,655 - INFO - Generated Story: A story about  a  middle - aged  white  man  with  a  shaved  head ,  wearing  a  black  t
2025-12-28 16:18:35,655 - INFO - Validation loss did not improve. Current best loss: 1.2415 (Patience: 4/5)
2025-12-28 16:18:36,791 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 9)
2025-12-28 16:18:51,885 - INFO - Epoch [10] Batch [0/3625] loss: 0.6913 
2025-12-28 16:22:14,746 - INFO - Epoch [10] Batch [1200/3625] loss: 0.6918 
2025-12-28 16:25:36,838 - INFO - Epoch [10] Batch [2400/3625] loss: 0.7000 
2025-12-28 16:28:59,539 - INFO - Epoch [10] Batch [3600/3625] loss: 0.8172 
2025-12-28 16:29:19,366 - INFO - Epoch [10] Batch [0/127] loss: 1.2986 
2025-12-28 16:29:23,104 - INFO - Epoch [10] Batch [60/127] loss: 1.4000 
2025-12-28 16:29:26,863 - INFO - Epoch [10] Batch [120/127] loss: 1.4502 
2025-12-28 16:29:27,929 - INFO - Epoch: [10/20]Train loss: 0.7170 | Val loss: 1.4255
2025-12-28 16:29:27,929 - INFO - --- Generating Sample Story for Epoch 10 ---
2025-12-28 16:29:28,459 - INFO - Generated Story: A story about  a  middle - aged  white  man  with  a  shaved  head ,  wearing  a  black  t
2025-12-28 16:29:28,459 - INFO - Validation loss did not improve. Current best loss: 1.2415 (Patience: 5/5)
2025-12-28 16:29:28,459 - INFO - Early stopping triggered after 5 epochs without improvement
2025-12-28 16:33:51,750 - INFO - Logging initialize successfully
2025-12-28 16:33:51,875 - INFO - Loaded 29000 rows for split='train'.
2025-12-28 16:33:51,994 - INFO - Loaded 1014 rows for split='val'.
2025-12-28 16:33:53,383 - INFO - Built 29000 samples from annotaions
2025-12-28 16:33:53,385 - INFO - Total train samples: 29000
2025-12-28 16:33:53,420 - INFO - Built 1014 samples from annotaions
2025-12-28 16:33:53,420 - INFO - Total val samples: 1014
2025-12-28 16:33:53,443 - INFO - Built 29000 samples for story 
2025-12-28 16:33:53,443 - INFO - Built 1014 samples for story 
2025-12-28 16:33:53,577 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-28 16:33:53,583 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-28 16:33:58,762 - INFO - Model initialized. Trainable parameters: 68534016
2025-12-28 16:34:00,440 - INFO - Checkpoint loaded from checkpoints/latest.pth. Resuming at epoch 9. (Scheduler restored: True, Scaler restored: True)
2025-12-28 16:34:00,440 - INFO - Checkpoint loaded from checkpoints/latest.pth (LATEST (Better Performance)). Resuming training from epoch 10, best loss tracked: 1.2415
2025-12-28 16:34:16,193 - INFO - Epoch [10] Batch [0/3625] loss: 0.7053 
2025-12-28 16:37:37,483 - INFO - Epoch [10] Batch [1200/3625] loss: 0.7091 
2025-12-28 16:41:05,300 - INFO - Epoch [10] Batch [2400/3625] loss: 0.8288 
2025-12-28 16:44:37,866 - INFO - Epoch [10] Batch [3600/3625] loss: 0.5913 
2025-12-28 16:45:06,493 - INFO - Epoch [10] Batch [0/127] loss: 1.3034 
2025-12-28 16:45:10,638 - INFO - Epoch [10] Batch [60/127] loss: 1.4027 
2025-12-28 16:45:14,737 - INFO - Epoch [10] Batch [120/127] loss: 1.4572 
2025-12-28 16:45:15,957 - INFO - Epoch: [10/20]Train loss: 0.7190 | Val loss: 1.4270
2025-12-28 16:45:15,958 - INFO - --- Generating Sample Story for Epoch 10 ---
2025-12-28 16:45:16,697 - INFO - Generated Story: A story about  a  middle - aged  white  man  with  a  shaved  head ,  wearing  a  black  t
2025-12-28 16:45:16,697 - INFO - Validation loss did not improve. Current best loss: 1.2415 (Patience: 1/7)
2025-12-28 16:45:17,981 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 10)
2025-12-28 16:45:40,014 - INFO - Epoch [11] Batch [0/3625] loss: 0.7019 
2025-12-29 14:59:59,469 - INFO - Logging initialize successfully
2025-12-29 14:59:59,612 - INFO - Loaded 29000 rows for split='train'.
2025-12-29 14:59:59,742 - INFO - Loaded 1014 rows for split='val'.
2025-12-29 15:00:01,156 - INFO - Built 29000 samples from annotaions
2025-12-29 15:00:01,158 - INFO - Total train samples: 29000
2025-12-29 15:00:01,196 - INFO - Built 1014 samples from annotaions
2025-12-29 15:00:01,196 - INFO - Total val samples: 1014
2025-12-29 15:00:01,220 - INFO - Built 29000 samples for story 
2025-12-29 15:00:01,221 - INFO - Built 1014 samples for story 
2025-12-29 15:00:01,358 - INFO - Cleaned data saved to data/processed\stories_train.jsonl
2025-12-29 15:00:01,364 - INFO - Cleaned data saved to data/processed\stories_val.jsonl
2025-12-29 15:00:06,012 - INFO - Model initialized. Trainable parameters: 68534016
2025-12-29 15:00:06,012 - INFO - Resume enabled but no valid checkpoint found. Starting from scratch.
2025-12-29 15:00:22,102 - INFO - Epoch [1] Batch [0/3625] loss: 74.4219 
2025-12-29 15:03:40,346 - INFO - Epoch [1] Batch [1200/3625] loss: 2.9005 
2025-12-29 15:07:01,992 - INFO - Epoch [1] Batch [2400/3625] loss: 2.4180 
2025-12-29 15:10:22,813 - INFO - Epoch [1] Batch [3600/3625] loss: 2.0337 
2025-12-29 15:10:43,611 - INFO - Epoch [1] Batch [0/127] loss: 2.3066 
2025-12-29 15:10:47,368 - INFO - Epoch [1] Batch [60/127] loss: 2.4892 
2025-12-29 15:10:51,124 - INFO - Epoch [1] Batch [120/127] loss: 2.4230 
2025-12-29 15:10:52,236 - INFO - Epoch: [1/20]Train loss: 3.0216 | Val loss: 2.4650
2025-12-29 15:10:52,236 - INFO - --- Generating Sample Story for Epoch 1 ---
2025-12-29 15:10:52,988 - INFO - Generated Story: A story about  a  woman  in  a  black  shirt  and  black  shorts ,  holding  a  white  bag .
2025-12-29 15:10:52,988 - INFO - Validation loss improved from 10.0000 to 2.4650. Saving Best model.
2025-12-29 15:10:53,975 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 1)
2025-12-29 15:10:54,986 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 1)
2025-12-29 15:11:10,327 - INFO - Epoch [2] Batch [0/3625] loss: 2.2368 
2025-12-29 15:14:29,766 - INFO - Epoch [2] Batch [1200/3625] loss: 2.7071 
2025-12-29 15:17:49,422 - INFO - Epoch [2] Batch [2400/3625] loss: 2.5018 
2025-12-29 15:21:10,047 - INFO - Epoch [2] Batch [3600/3625] loss: 2.3097 
2025-12-29 15:21:29,816 - INFO - Epoch [2] Batch [0/127] loss: 2.2191 
2025-12-29 15:21:33,577 - INFO - Epoch [2] Batch [60/127] loss: 2.3302 
2025-12-29 15:21:37,332 - INFO - Epoch [2] Batch [120/127] loss: 2.3503 
2025-12-29 15:21:38,419 - INFO - Epoch: [2/20]Train loss: 2.4166 | Val loss: 2.3635
2025-12-29 15:21:38,427 - INFO - --- Generating Sample Story for Epoch 2 ---
2025-12-29 15:21:39,006 - INFO - Generated Story: A story about  a  woman  in  a  black  shirt  and  black  pants ,  standing  on  a  sidewalk .
2025-12-29 15:21:39,006 - INFO - Validation loss improved from 2.4650 to 2.3635. Saving Best model.
2025-12-29 15:21:39,982 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 2)
2025-12-29 15:21:40,989 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 2)
2025-12-29 15:21:56,528 - INFO - Epoch [3] Batch [0/3625] loss: 2.3126 
2025-12-29 15:25:16,811 - INFO - Epoch [3] Batch [1200/3625] loss: 2.5609 
2025-12-29 15:52:40,123 - INFO - Epoch [3] Batch [2400/3625] loss: 2.0658 
2025-12-29 15:55:58,561 - INFO - Epoch [3] Batch [3600/3625] loss: 2.4235 
2025-12-29 15:56:18,775 - INFO - Epoch [3] Batch [0/127] loss: 2.1799 
2025-12-29 15:56:22,476 - INFO - Epoch [3] Batch [60/127] loss: 2.2831 
2025-12-29 15:56:26,203 - INFO - Epoch [3] Batch [120/127] loss: 2.2599 
2025-12-29 15:56:27,247 - INFO - Epoch: [3/20]Train loss: 2.2689 | Val loss: 2.3230
2025-12-29 15:56:27,247 - INFO - --- Generating Sample Story for Epoch 3 ---
2025-12-29 15:56:27,788 - INFO - Generated Story: A story about  a  woman  in  a  red  shirt  and  black  pants ,  standing  on  a  sidewalk .
2025-12-29 15:56:27,799 - INFO - Validation loss improved from 2.3635 to 2.3230. Saving Best model.
2025-12-29 15:56:28,747 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 3)
2025-12-29 15:56:29,736 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 3)
2025-12-29 15:56:44,894 - INFO - Epoch [4] Batch [0/3625] loss: 1.8597 
2025-12-29 16:00:03,964 - INFO - Epoch [4] Batch [1200/3625] loss: 2.3407 
2025-12-29 16:03:23,732 - INFO - Epoch [4] Batch [2400/3625] loss: 2.0831 
2025-12-29 16:06:45,129 - INFO - Epoch [4] Batch [3600/3625] loss: 1.9902 
2025-12-29 16:07:06,191 - INFO - Epoch [4] Batch [0/127] loss: 2.1437 
2025-12-29 16:07:09,996 - INFO - Epoch [4] Batch [60/127] loss: 2.3085 
2025-12-29 16:07:13,810 - INFO - Epoch [4] Batch [120/127] loss: 2.2487 
2025-12-29 16:07:14,947 - INFO - Epoch: [4/20]Train loss: 2.1626 | Val loss: 2.3172
2025-12-29 16:07:14,947 - INFO - --- Generating Sample Story for Epoch 4 ---
2025-12-29 16:07:15,545 - INFO - Generated Story: A story about  a  man  in  a  blue  shirt  and  black  pants ,  standing  on  a  sidewalk .
2025-12-29 16:07:15,545 - INFO - Validation loss improved from 2.3230 to 2.3172. Saving Best model.
2025-12-29 16:07:16,539 - INFO - Checkpoint saved to checkpoints/best.pth (resumption epoch: 4)
2025-12-29 16:07:17,586 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 4)
2025-12-29 16:07:33,314 - INFO - Epoch [5] Batch [0/3625] loss: 2.0509 
2025-12-29 16:10:53,139 - INFO - Epoch [5] Batch [1200/3625] loss: 2.1130 
2025-12-29 16:14:12,855 - INFO - Epoch [5] Batch [2400/3625] loss: 2.0025 
2025-12-29 16:17:32,049 - INFO - Epoch [5] Batch [3600/3625] loss: 1.9045 
2025-12-29 16:17:51,608 - INFO - Epoch [5] Batch [0/127] loss: 2.2011 
2025-12-29 16:17:55,322 - INFO - Epoch [5] Batch [60/127] loss: 2.2547 
2025-12-29 16:17:59,050 - INFO - Epoch [5] Batch [120/127] loss: 2.2686 
2025-12-29 16:18:00,082 - INFO - Epoch: [5/20]Train loss: 2.0710 | Val loss: 2.3205
2025-12-29 16:18:00,082 - INFO - --- Generating Sample Story for Epoch 5 ---
2025-12-29 16:18:00,587 - INFO - Generated Story: A story about  a  woman  in  a  white  shirt  and  black  pants ,  standing  on  a  sidewalk .
2025-12-29 16:18:00,587 - INFO - Validation loss did not improve. Current best loss: 2.3172 (Patience: 1/7)
2025-12-29 16:18:01,603 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 5)
2025-12-29 16:18:16,925 - INFO - Epoch [6] Batch [0/3625] loss: 2.1235 
2025-12-29 16:21:35,634 - INFO - Epoch [6] Batch [1200/3625] loss: 2.0850 
2025-12-29 16:24:54,934 - INFO - Epoch [6] Batch [2400/3625] loss: 1.9067 
2025-12-29 16:28:14,377 - INFO - Epoch [6] Batch [3600/3625] loss: 2.0338 
2025-12-29 16:28:33,966 - INFO - Epoch [6] Batch [0/127] loss: 2.2060 
2025-12-29 16:28:37,699 - INFO - Epoch [6] Batch [60/127] loss: 2.2951 
2025-12-29 16:28:41,410 - INFO - Epoch [6] Batch [120/127] loss: 2.2806 
2025-12-29 16:28:42,447 - INFO - Epoch: [6/20]Train loss: 1.9947 | Val loss: 2.3347
2025-12-29 16:28:42,447 - INFO - --- Generating Sample Story for Epoch 6 ---
2025-12-29 16:28:43,049 - INFO - Generated Story: A story about  a  man  in  a  white  shirt  and  black  pants ,  holding  a  black  and  white
2025-12-29 16:28:43,049 - INFO - Validation loss did not improve. Current best loss: 2.3172 (Patience: 2/7)
2025-12-29 16:28:44,113 - INFO - Checkpoint saved to checkpoints/latest.pth (resumption epoch: 6)
2025-12-29 16:29:00,980 - INFO - Epoch [7] Batch [0/3625] loss: 1.8428 
